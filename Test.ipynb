{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from Utils import Utils\n",
    "\n",
    "csv_path = \"/Users/shantanughosh/Desktop/Shantanu_MS/Research/Mattia_Prosperi/Propensity_Dropout/Dataset/ihdp_sample.csv\"\n",
    "\n",
    "from dataloader import DataLoader\n",
    "\n",
    "dL = DataLoader()\n",
    "split_size = 0.8\n",
    "# np_covariates_X_train, np_covariates_X_test, \\\n",
    "# np_covariates_Y_train, np_covariates_Y_test = dL.preprocess_data_from_csv(csv_path, split_size=0.8)\n",
    "# norm_X_train = np_covariates_X_train / np.linalg.norm(np_covariates_X_train)\n",
    "# ps_train_set = dL.convert_to_tensor(np_covariates_X_train, np_covariates_Y_train)\n",
    "# device = Utils.get_device()\n",
    "\n",
    "# print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. Data Loading synthetic..\n",
      "std dev\n",
      "ps_np_covariates_X: (747, 77)\n",
      "ps_np_treatment_Y: (747, 1)\n",
      "np_covariates_X_train: (597, 77)\n",
      "np_covariates_Y_train: (597, 1)\n",
      "------------------------------------------------------------\n",
      "np_covariates_X_test: (150, 77)\n",
      "np_covariates_Y_test: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "np_covariates_X_train, np_covariates_X_test, np_covariates_Y_train, np_covariates_Y_test = \\\n",
    "                dL.preprocess_data_from_csv_augmented(csv_path, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 1.5 6.5 4.5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1], [2], [3]])\n",
    "y = np.array([[4, 5, 6, 9], [7, 8, 19, 18]])\n",
    "y1 = y\n",
    "np.random.seed(0)\n",
    "std = np.std(y, axis=0)\n",
    "print(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time:2020-06-28 02:31:07.035978\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Current date time in local system\n",
    "start = datetime.now()\n",
    "print(\"start_time:\" + str(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration : 0:00:10.656428\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration : \" + str( start - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now:2020-06-28 02:30:31.358836\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "print(\"now:\" + str(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "1.5\n",
      "1.5\n",
      "6.5\n",
      "4.5\n",
      "[[ 5.1863139   5.1863139  22.47402689 15.55894169]\n",
      " [ 5.1863139   5.1863139  22.47402689 15.55894169]]\n",
      "[[ 9.1863139  10.1863139  28.47402689 24.55894169]\n",
      " [12.1863139  13.1863139  41.47402689 33.55894169]]\n",
      "33.558941691434796\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(std.shape[0])\n",
    "y = np.array([[4, 5, 6, 9], [7, 8, 19, 18]])\n",
    "id = -1\n",
    "noise = np.empty([y.shape[0], y.shape[1]])\n",
    "for s in std:\n",
    "    id +=1\n",
    "    print(s)\n",
    "    np.random.seed(0)\n",
    "#     noise[:, id] = s\n",
    "    \n",
    "    noise[:, id] = np.random.normal(0, 1.96 * s)\n",
    "    \n",
    "print(noise)\n",
    "\n",
    "noise_y = noise + y\n",
    "\n",
    "print(noise_y)\n",
    "\n",
    "np.random.seed(0)\n",
    "print(18 + np.random.normal(0, 1.96 * 4.5))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.        ,  5.        ,  6.        ,  9.        ,  9.1863139 ,\n",
       "        10.1863139 , 28.47402689, 24.55894169],\n",
       "       [ 7.        ,  8.        , 19.        , 18.        , 12.1863139 ,\n",
       "        13.1863139 , 41.47402689, 33.55894169]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_covariates_X = np.concatenate((y, noise_y), axis=1)\n",
    "np_covariates_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.46065812, 3.0567042 , 2.11719028, ..., 4.28878054, 3.10172903,\n",
       "        1.54447345],\n",
       "       [9.79916421, 6.72271051, 0.56458668, ..., 6.61807015, 0.84864102,\n",
       "        2.20950882],\n",
       "       [3.08468093, 0.80308587, 8.23004286, ..., 9.35602002, 4.00396147,\n",
       "        3.45538455],\n",
       "       ...,\n",
       "       [7.6659666 , 5.92223383, 5.4396373 , ..., 2.00343179, 3.31540825,\n",
       "        5.78755804],\n",
       "       [7.03123107, 5.19232512, 0.0989919 , ..., 2.46743731, 8.43478922,\n",
       "        1.385397  ],\n",
       "       [6.85562166, 5.98248875, 0.6526608 , ..., 8.12321355, 2.73154856,\n",
       "        0.28318412]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nrandom = np.random.random((747,25)) *10\n",
    "nrandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Sparse_Propensity_score import Sparse_Propensity_score\n",
    "train_parameters_SAE = {\n",
    "            \"epochs\": 200,\n",
    "            \"lr\": 0.0001,\n",
    "            \"batch_size\": 32,\n",
    "            \"shuffle\": True,\n",
    "            \"train_set\": ps_train_set,\n",
    "            \"sparsity_probability\": 0.08,\n",
    "            \"weight_decay\": 0.0003,\n",
    "            \"BETA\": 0.4,\n",
    "            \"model_save_path\": \"./Propensity_Model/SAE_PS_model_iter_id_\"\n",
    "                               + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "        }\n",
    "\n",
    "# train_parameters_SAE = {\n",
    "#     \"epochs\": 20,\n",
    "#     \"lr\": 0.001,\n",
    "#     \"batch_size\": 32,\n",
    "#     \"shuffle\": True,\n",
    "#     \"train_set\": ps_train_set,\n",
    "#     \"sparsity_probability\": 0.05,\n",
    "#     \"weight_decay\": 0.0003,\n",
    "#     \"BETA\": 3,\n",
    "#     \"model_save_path\": \"./Propensity_Model/SAE_PS_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "# }\n",
    "\n",
    "# train_parameters_SAE = {\n",
    "#     \"epochs\": 200,\n",
    "#     \"lr\": 0.0001,\n",
    "#     \"batch_size\": 32,\n",
    "#     \"shuffle\": True,\n",
    "#     \"train_set\": ps_train_set,\n",
    "#     \"sparsity_probability\": 0.08,\n",
    "#     \"weight_decay\": 0.0003,\n",
    "#     \"BETA\": 0.4,\n",
    "#     \"model_save_path\": \"./Propensity_Model/SAE_PS_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "# }\n",
    "\n",
    "ps_net_SAE = Sparse_Propensity_score()\n",
    "print(\"############### Propensity Score SAE net Training ###############\")\n",
    "sparse_classifier, sae_classifier_stacked_all_layer_active, sae_classifier_stacked_cur_layer_active = ps_net_SAE.train(train_parameters_SAE, device, phase=\"train\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(ps_train_set, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_list_SAE = ps_net_SAE.eval(ps_train_set, device, phase=\"eval\", sparse_classifier=sparse_classifier)\n",
    "ps_score_list_SAE_all_stacked = ps_net_SAE.eval(ps_train_set, device, phase=\"eval\", \n",
    "                                                sparse_classifier=sae_classifier_stacked_all_layer_active)\n",
    "ps_score_list_SAE_cur_stacked = ps_net_SAE.eval(ps_train_set, device, phase=\"eval\", \n",
    "                                                sparse_classifier=sae_classifier_stacked_cur_layer_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Propensity_socre_network import Propensity_socre_network\n",
    "train_parameters_NN = {\n",
    "        \"epochs\": 100,\n",
    "        \"lr\": 0.001,\n",
    "        \"batch_size\": 32,\n",
    "        \"shuffle\": True,\n",
    "        \"train_set\": ps_train_set,\n",
    "        \"model_save_path\": \"./Propensity_Model/NN_PS_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "}\n",
    "ps_net_NN = Propensity_socre_network()\n",
    "print(\"############### Propensity Score neural net Training ###############\")\n",
    "ps_net_NN.train(train_parameters_NN, device, phase=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval propensity network using NN\n",
    "eval_parameters_NN = {\n",
    "        \"eval_set\": ps_train_set,\n",
    "        \"model_path\": \"./Propensity_Model/NN_PS_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "}\n",
    "\n",
    "ps_score_list_NN = ps_net_NN.eval(eval_parameters_NN, device, phase=\"eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_score_list_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DCN_network import DCN_network\n",
    "\n",
    "def train_DCN(data_loader_dict, model_path, dL, device):\n",
    "    treated_group = data_loader_dict[\"treated_data\"]\n",
    "    np_treated_df_X = treated_group[0]\n",
    "    np_treated_ps_score = treated_group[1]\n",
    "    np_treated_df_Y_f = treated_group[2]\n",
    "    np_treated_df_Y_cf = treated_group[3]\n",
    "    tensor_treated = dL.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                              np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "    control_group = data_loader_dict[\"control_data\"]\n",
    "    np_control_df_X = control_group[0]\n",
    "    np_control_ps_score = control_group[1]\n",
    "    np_control_df_Y_f = control_group[2]\n",
    "    np_control_df_Y_cf = control_group[3]\n",
    "    tensor_control = dL.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                              np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "    DCN_train_parameters = {\n",
    "        \"epochs\": 100,\n",
    "        \"lr\": 0.001,\n",
    "        \"treated_batch_size\": 1,\n",
    "        \"control_batch_size\": 1,\n",
    "        \"shuffle\": True,\n",
    "        \"treated_set\": tensor_treated,\n",
    "        \"control_set\": tensor_control,\n",
    "        \"model_save_path\": model_path\n",
    "    }\n",
    "\n",
    "    # train DCN network\n",
    "    dcn = DCN_network()\n",
    "    dcn.train(DCN_train_parameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Training using NN ###############\")\n",
    "data_loader_dict_NN = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                    np_covariates_Y_train,\n",
    "                                                    ps_score_list_NN)\n",
    "model_path = \"./DCNModel/NN_DCN_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "train_DCN(data_loader_dict_NN, model_path, dL, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Training using Sparse ###############\")\n",
    "data_loader_dict_SAE = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                     np_covariates_Y_train,\n",
    "                                                     ps_score_list_SAE)\n",
    "\n",
    "data_loader_dict_SAE_all_stacked = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                     np_covariates_Y_train,\n",
    "                                                     ps_score_list_SAE_all_stacked)\n",
    "\n",
    "data_loader_dict_SAE_cur_stacked = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                     np_covariates_Y_train,\n",
    "                                                     ps_score_list_SAE_cur_stacked)\n",
    "print(\"e2e\")\n",
    "model_path = \"./DCNModel/SAE_DCN_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "train_DCN(data_loader_dict_SAE, model_path, dL, device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all stacked\")\n",
    "model_path = \"./DCNModel/SAE_all_stacked_DCN_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "train_DCN(data_loader_dict_SAE_all_stacked, model_path, dL, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cur stacked\")\n",
    "model_path = \"./DCNModel/SAE_cur_stacked_DCN_model_iter_id_\" + str(1) + \"_epoch_{0}_lr_{1}.pth\"\n",
    "train_DCN(data_loader_dict_SAE_cur_stacked, model_path, dL, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_test_set = dL.convert_to_tensor(np_covariates_X_test, np_covariates_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_parameters_sparse_test = {\n",
    "        \"eval_set\": ps_test_set\n",
    "}\n",
    "\n",
    "ps_score_list_sparse = ps_net_SAE.eval(ps_test_set, device, phase=\"eval\", sparse_classifier=sparse_classifier)\n",
    "ps_score_list_sparse_all_stacked = ps_net_SAE.eval(ps_test_set, device, phase=\"eval\", \n",
    "                                       sparse_classifier=sae_classifier_stacked_all_layer_active)\n",
    "ps_score_list_sparse_cur_stacked = ps_net_SAE.eval(ps_test_set, device, phase=\"eval\", \n",
    "                                       sparse_classifier=sae_classifier_stacked_cur_layer_active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval propensity network using NN\n",
    "eval_parameters_NN = {\n",
    "        \"eval_set\": ps_test_set,\n",
    "        \"model_path\": \"./Propensity_Model/NN_PS_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "}\n",
    "\n",
    "ps_score_list_NN = ps_net_NN.eval(eval_parameters_NN, device, phase=\"eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_test_DCN(data_loader_dict, dL, device, model_path):\n",
    "    treated_group = data_loader_dict[\"treated_data\"]\n",
    "    np_treated_df_X = treated_group[0]\n",
    "    np_treated_ps_score = treated_group[1]\n",
    "    np_treated_df_Y_f = treated_group[2]\n",
    "    np_treated_df_Y_cf = treated_group[3]\n",
    "    tensor_treated = dL.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                              np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "    control_group = data_loader_dict[\"control_data\"]\n",
    "    np_control_df_X = control_group[0]\n",
    "    np_control_ps_score = control_group[1]\n",
    "    np_control_df_Y_f = control_group[2]\n",
    "    np_control_df_Y_cf = control_group[3]\n",
    "    tensor_control = dL.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                              np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "    DCN_test_parameters = {\n",
    "        \"treated_set\": tensor_treated,\n",
    "        \"control_set\": tensor_control,\n",
    "        \"model_save_path\": model_path\n",
    "    }\n",
    "\n",
    "    dcn = DCN_network()\n",
    "    err_dict = dcn.eval(DCN_test_parameters, device)\n",
    "    err_treated = [ele ** 2 for ele in err_dict[\"treated_err\"]]\n",
    "    err_control = [ele ** 2 for ele in err_dict[\"control_err\"]]\n",
    "\n",
    "    total_sum = sum(err_treated) + sum(err_control)\n",
    "    total_item = len(err_treated) + len(err_control)\n",
    "    MSE = total_sum / total_item\n",
    "    print(\"MSE: {0}\".format(MSE))\n",
    "    max_treated = max(err_treated)\n",
    "    max_control = max(err_control)\n",
    "    max_total = max(max_treated, max_control)\n",
    "\n",
    "    min_treated = min(err_treated)\n",
    "    min_control = min(err_control)\n",
    "    min_total = min(min_treated, min_control)\n",
    "\n",
    "    print(\"Max: {0}, Min: {1}\".format(max_total, min_total))\n",
    "    return MSE\n",
    "    # np.save(\"treated_err.npy\", err_treated)\n",
    "    # np.save(\"control_err.npy\", err_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Testing using NN ###############\")\n",
    "data_loader_dict_NN = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                    np_covariates_Y_test,\n",
    "                                                    ps_score_list_NN)\n",
    "model_path = \"./DCNModel/NN_DCN_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "MSE_NN = do_test_DCN(data_loader_dict_NN, dL, device, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Testing using SAE e2e ###############\")\n",
    "data_loader_dict_SAE = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                     np_covariates_Y_test,\n",
    "                                                     ps_score_list_sparse)\n",
    "model_path = \"./DCNModel/SAE_DCN_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "MSE_SAE = do_test_DCN(data_loader_dict_SAE, dL, device, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Testing using SAE all stacked ###############\")\n",
    "data_loader_dict_SAE = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                     np_covariates_Y_test,\n",
    "                                                     ps_score_list_sparse_all_stacked)\n",
    "model_path = \"./DCNModel/SAE_all_stacked_DCN_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "MSE_SAE = do_test_DCN(data_loader_dict_SAE, dL, device, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############### DCN Testing using SAE cur stacked ###############\")\n",
    "data_loader_dict_SAE = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                     np_covariates_Y_test,\n",
    "                                                     ps_score_list_sparse_cur_stacked)\n",
    "model_path = \"./DCNModel/SAE_cur_stacked_DCN_model_iter_id_{0}_epoch_100_lr_0.001.pth\".format(1)\n",
    "MSE_SAE = do_test_DCN(data_loader_dict_SAE, dL, device, model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
