{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from Utils import Utils\n",
    "from Constants import Constants\n",
    "from Propensity_socre_network import Propensity_socre_network\n",
    "from Utils import Utils\n",
    "from PS_Manager import PS_Manager\n",
    "from PS_Treated_Generator import PS_Treated_Generator\n",
    "\n",
    "from GAN import Generator, Discriminator\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from GAN_Manager import GAN_Manager\n",
    "from Utils import Utils\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from torch.autograd.variable import Variable\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from GAN_Manager import GAN_Manager\n",
    "from Utils import Utils\n",
    "\n",
    "def get_matched_and_unmatched_control_indices(ps_treated, ps_control):\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(ps_control)\n",
    "    distance, matched_control = nn.kneighbors(ps_treated)\n",
    "    matched_control_indices = np.array(matched_control).ravel()\n",
    "\n",
    "        # # remove duplicates\n",
    "    #matched_control_indices = list(dict.fromkeys(matched_control_indices))\n",
    "    set_matched_control_indices = set(matched_control_indices)\n",
    "    total_indices = list(range(len(ps_control)))\n",
    "    unmatched_control_indices = list(filter(lambda x: x not in set_matched_control_indices,\n",
    "                                                total_indices))\n",
    "\n",
    "    return matched_control_indices, unmatched_control_indices\n",
    "\n",
    "def filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                              np_control_df_Y_f,\n",
    "                              np_control_df_Y_cf, indices):\n",
    "    np_filter_control_df_X = np.take(np_control_df_X, indices, axis=0)\n",
    "    np_filter_control_ps_score = np.take(np_control_ps_score, indices, axis=0)\n",
    "    np_filter_control_df_Y_f = np.take(np_control_df_Y_f, indices, axis=0)\n",
    "    np_filter_control_df_Y_cf = np.take(np_control_df_Y_cf, indices, axis=0)\n",
    "    tuple_matched_control = (np_filter_control_df_X, np_filter_control_ps_score,\n",
    "                                 np_filter_control_df_Y_f, np_filter_control_df_Y_cf)\n",
    "\n",
    "    return tuple_matched_control\n",
    "\n",
    "def filter_matched_and_unmatched_control_samples(np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f,\n",
    "                                                     np_control_df_Y_cf, matched_control_indices,\n",
    "                                                     unmatched_control_indices):\n",
    "    tuple_matched_control = filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                                                           np_control_df_Y_f,\n",
    "                                                           np_control_df_Y_cf,\n",
    "                                                           matched_control_indices)\n",
    "\n",
    "    tuple_unmatched_control = filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                                                             np_control_df_Y_f,\n",
    "                                                             np_control_df_Y_cf,\n",
    "                                                             unmatched_control_indices)\n",
    "\n",
    "    return tuple_matched_control, tuple_unmatched_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ps_model(ps_model_type, iter_id,\n",
    "                       input_nodes, device, \n",
    "                 np_covariates_X_train, np_covariates_X_test, np_covariates_Y_train, \n",
    "                 np_covariates_Y_test, dL):\n",
    "    ps_train_set = dL.convert_to_tensor(np_covariates_X_train, \n",
    "                                             np_covariates_Y_train)\n",
    "    ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                            np_covariates_Y_test)\n",
    "    ps_manager = PS_Manager()\n",
    "    if ps_model_type == Constants.PS_MODEL_NN:\n",
    "        return ps_manager.get_propensity_scores(ps_train_set,\n",
    "                                                    ps_test_set, iter_id,\n",
    "                                                    input_nodes, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Propensity Score neural net Training ###############\n",
      ".. PS Training started ..\n",
      "Epoch: 25, loss: 6.894181028008461, correct: 487/597, accuracy: 0.8157453936348409\n",
      "Epoch: 50, loss: 4.5601475685834885, correct: 527/597, accuracy: 0.8827470686767169\n",
      "Training Completed..\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"Dataset/ihdp_sample.csv\"\n",
    "from dataloader import DataLoader\n",
    "split_size = 0.8\n",
    "dL = DataLoader()\n",
    "iter_id = 1\n",
    "input_nodes = 25\n",
    "device = Utils.get_device()\n",
    "\n",
    "np_covariates_X_train, np_covariates_X_test, np_covariates_Y_train, np_covariates_Y_test \\\n",
    "                = dL.preprocess_data_from_csv(csv_path, split_size)\n",
    "\n",
    "ps_train_set = dL.convert_to_tensor(np_covariates_X_train, np_covariates_Y_train)\n",
    "# ps_score_list_train_NN = get_propensity_scores(ps_train_set, iter_id, input_nodes, device)\n",
    "\n",
    "ps_model_type=Constants.PS_MODEL_NN\n",
    "ps_score_list_train, ps_score_list_test, ps_model = get_ps_model(ps_model_type,iter_id,\n",
    "                                                                input_nodes,\n",
    "                                                                device,\n",
    "                                                                np_covariates_X_train, np_covariates_X_test, \n",
    "                                                                np_covariates_Y_train, \n",
    "                                                                np_covariates_Y_test, dL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_score_list_train_NN = ps_score_list_train\n",
    "print(len(ps_score_list_train_NN))\n",
    "len(ps_score_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Treated Statistics ==>\n",
      "(110, 25)\n",
      " Control Statistics ==>\n",
      "(487, 25)\n"
     ]
    }
   ],
   "source": [
    "data_loader_dict_train = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                              np_covariates_Y_train,\n",
    "                                                              ps_score_list_train_NN,\n",
    "                                                              False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Control: 110\n",
      "Unmatched Control: 440\n",
      "Matched Control: (110, 25)\n",
      "Matched Treated: (110, 25)\n"
     ]
    }
   ],
   "source": [
    "tuple_treated = data_loader_dict_train[\"treated_data\"]\n",
    "tuple_control = data_loader_dict_train[\"control_data\"]\n",
    "np_treated_df_X, np_treated_ps_score, np_treated_df_Y_f, np_treated_df_Y_cf = tuple_treated\n",
    "np_control_df_X, np_control_ps_score, np_control_df_Y_f, np_control_df_Y_cf = tuple_control\n",
    "\n",
    "        # get unmatched controls\n",
    "matched_control_indices, unmatched_control_indices = get_matched_and_unmatched_control_indices(\n",
    "Utils.convert_to_col_vector(np_treated_ps_score),\n",
    "Utils.convert_to_col_vector(np_control_ps_score))\n",
    "\n",
    "print(\"Matched Control: {0}\".format(len(matched_control_indices)))\n",
    "print(\"Unmatched Control: {0}\".format(len(unmatched_control_indices)))\n",
    "\n",
    "tuple_matched_control, tuple_unmatched_control = filter_matched_and_unmatched_control_samples(\n",
    "            np_control_df_X, np_control_ps_score,\n",
    "            np_control_df_Y_f,\n",
    "            np_control_df_Y_cf, matched_control_indices,\n",
    "            unmatched_control_indices)\n",
    "\n",
    "        # generate matched treated for unmatched controls using variable\n",
    "        # tuple_unmatched_control\n",
    "        # create GAN code here\n",
    "print(\"Matched Control: {0}\".format(tuple_matched_control[0].shape))\n",
    "print(\"Matched Treated: {0}\".format(tuple_treated[0].shape))\n",
    "tensor_treated = \\\n",
    "            Utils.create_tensors_to_train_DCN(tuple_treated, dL)\n",
    "\n",
    "        # need to change for unmatched\n",
    "tensor_matched_control = \\\n",
    "            Utils.create_tensors_to_train_DCN(tuple_matched_control, dL)\n",
    "\n",
    "tensor_unmatched_control = \\\n",
    "            Utils.create_tensors_to_train_DCN(tuple_unmatched_control, dL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([[ 6.5097e-04, -1.7002e-02, -3.0651e-01, -1.6960e-01, -1.8312e-01,\n",
      "         -1.4993e-01, -1.4131e-01,  7.5601e-02,  1.0128e-02, -5.9462e-02,\n",
      "          5.5825e-02,  3.9940e-02,  2.2372e-01, -4.0432e-02, -3.8436e-02,\n",
      "         -8.0285e-02,  3.7613e-02, -1.5925e-01, -1.8394e-01,  2.2996e-01,\n",
      "          1.5143e-01,  1.7001e-01,  2.2519e-01, -2.9983e-02, -6.2041e-02],\n",
      "        [ 8.3384e-02, -3.6643e-02, -3.3339e-01, -7.2526e-02,  2.1678e-01,\n",
      "         -1.0436e-01,  2.1112e-01, -2.6544e-01,  4.5422e-02,  4.9079e-02,\n",
      "         -2.8169e-01,  9.1486e-03, -1.9106e-01, -4.2072e-02, -1.3664e-01,\n",
      "          4.4773e-02,  6.8548e-02, -2.1993e-02, -1.7416e-01,  4.4245e-02,\n",
      "          1.2394e-01,  3.3318e-01,  3.1456e-01,  1.4697e-01, -2.5896e-01],\n",
      "        [ 6.2710e-03, -3.5689e-03,  3.9943e-02,  1.9882e-01,  1.0505e-01,\n",
      "          2.5068e-02,  2.9301e-02, -1.0379e-01, -1.8220e-01, -1.8106e-01,\n",
      "          1.0037e-01,  4.5255e-02, -2.9388e-01,  4.1484e-02,  5.3230e-02,\n",
      "          1.6032e-01, -1.1235e-01,  1.0805e-02,  2.4644e-01,  1.9559e-02,\n",
      "         -1.4402e-01,  1.8607e-01,  1.1136e-01,  1.4614e-01, -7.8670e-05],\n",
      "        [ 6.6255e-02,  2.2266e-02,  2.8825e-01,  5.5031e-02, -6.6849e-02,\n",
      "          1.4255e-01, -2.6789e-01,  7.6358e-03,  5.4610e-02, -3.2082e-02,\n",
      "          1.2095e-01,  1.8891e-01, -2.7715e-01, -1.0676e-01, -3.8018e-02,\n",
      "          1.2167e-01, -4.6632e-02,  6.0981e-02,  2.5891e-01,  3.4212e-01,\n",
      "          2.3353e-01,  1.2758e-01, -1.1239e-01,  9.0092e-03, -1.6333e-02],\n",
      "        [-6.9909e-02, -1.3890e-01, -1.3909e-01, -1.4620e-01, -1.1312e-01,\n",
      "          1.0727e-01,  1.7131e-01,  3.2599e-01,  4.0278e-02,  2.9481e-01,\n",
      "         -8.4775e-02,  5.8921e-02,  2.5423e-01, -1.9684e-01,  2.6455e-01,\n",
      "         -4.6124e-02, -6.2781e-02, -2.6921e-01, -2.3445e-02,  7.3132e-02,\n",
      "          4.1609e-02, -8.0921e-02,  1.1365e-01, -2.9043e-02,  1.3955e-01],\n",
      "        [-1.0116e-01,  2.8450e-02, -7.2376e-02, -5.7782e-02,  1.1536e-01,\n",
      "          1.2387e-01,  1.3766e-01, -1.6177e-01,  2.0750e-01,  1.7089e-01,\n",
      "         -1.2042e-01,  1.7359e-01,  1.3870e-01,  5.9653e-02,  1.8276e-01,\n",
      "          2.3206e-01, -1.3979e-01,  5.5347e-02, -1.0800e-01,  3.3106e-01,\n",
      "         -1.3707e-02,  1.2245e-01,  1.2965e-01,  1.9647e-01,  1.6987e-01],\n",
      "        [-6.1220e-02, -2.5249e-01, -1.0193e-01,  1.9158e-01,  1.3015e-01,\n",
      "         -5.4985e-02,  2.5865e-01, -2.1867e-01, -3.0881e-01,  3.6855e-01,\n",
      "          2.3417e-01, -2.4388e-02, -1.6807e-01, -1.6482e-01,  2.6145e-01,\n",
      "          9.4210e-03,  9.0027e-02,  4.8369e-02,  5.6364e-02,  2.8081e-01,\n",
      "         -2.9827e-01,  1.0607e-01,  2.7785e-01,  3.7268e-02,  4.2498e-02],\n",
      "        [-8.6312e-02, -5.2000e-02, -6.7352e-02, -5.1679e-02, -1.5454e-01,\n",
      "          5.0463e-02, -3.8606e-01, -6.1476e-01, -4.5743e-01,  1.7236e-01,\n",
      "          5.4499e-03,  2.7346e-01,  4.5385e-02, -7.4468e-02,  1.2071e-01,\n",
      "          5.1901e-02,  2.7355e-01,  1.6524e-01, -8.8243e-02, -2.8966e-01,\n",
      "         -1.6026e-02, -2.5212e-01, -4.2129e-01, -2.4550e-01,  1.1258e-01],\n",
      "        [-3.0892e-02, -1.2110e-02, -1.1833e-03, -1.9209e-03,  5.6092e-02,\n",
      "         -4.0914e-03, -1.7272e-01,  1.1857e-01, -2.0219e-01, -3.2226e-01,\n",
      "          7.8877e-02,  1.5409e-01,  1.1931e-01,  2.2026e-02,  8.8707e-02,\n",
      "         -1.3182e-01,  1.4185e-01, -5.5352e-02,  3.3209e-01,  1.7154e-02,\n",
      "         -1.9238e-01,  5.3076e-02,  4.0580e-01,  3.8435e-02, -3.6967e-01],\n",
      "        [ 5.6061e-02,  8.6996e-02, -8.8876e-02,  2.0114e-01, -5.4509e-03,\n",
      "          7.4715e-02,  2.0000e-01, -2.0761e-03,  2.0784e-01,  1.2720e-03,\n",
      "          1.9948e-01, -1.2561e-01,  1.6994e-02, -1.9743e-01, -3.8135e-03,\n",
      "          6.5204e-02, -9.1889e-02,  1.1637e-01, -1.0039e-01, -5.9431e-01,\n",
      "          5.4473e-02,  1.9889e-02,  2.1814e-01,  2.8995e-01, -1.4887e-01],\n",
      "        [ 1.3972e-01,  1.1067e-01,  1.6157e-01,  5.6214e-02,  1.6549e-01,\n",
      "         -1.6004e-01,  4.6795e-02, -2.1860e-01, -4.0691e-02, -5.4910e-02,\n",
      "          5.8114e-02,  8.7438e-02, -1.7342e-01,  2.4655e-02, -6.5601e-02,\n",
      "          2.0160e-01,  2.3381e-01, -1.8219e-01, -1.3385e-01, -2.0386e-03,\n",
      "          1.3044e-01,  7.2371e-02,  2.3052e-01,  4.8982e-02, -1.4803e-01],\n",
      "        [-7.0423e-02,  2.4590e-02,  3.0547e-01,  1.1566e-01, -1.7699e-02,\n",
      "         -1.2647e-01, -1.5640e-01,  2.3379e-01, -4.8408e-03,  8.2627e-02,\n",
      "         -1.2881e-01,  2.4913e-01, -2.5233e-01, -9.6157e-02,  2.5891e-01,\n",
      "          1.1867e-02, -1.0779e-01,  9.8696e-02,  2.3675e-02,  3.8278e-01,\n",
      "          1.1848e-01,  1.8344e-01,  2.6035e-01,  2.8126e-01, -2.5489e-01],\n",
      "        [-4.6335e-02,  4.3683e-02, -9.8759e-02,  4.1059e-02,  1.3826e-01,\n",
      "         -9.1813e-02, -1.2273e-01, -4.0107e-02, -1.9695e-01,  1.5609e-01,\n",
      "          4.5581e-02, -8.5099e-03,  9.3590e-02, -1.7974e-01, -1.1476e-01,\n",
      "          3.6034e-02,  9.4547e-02,  1.3885e-01, -1.4426e-01,  2.7791e-01,\n",
      "          9.4792e-03,  4.2069e-01,  2.8669e-01,  3.6373e-02, -1.6531e-01],\n",
      "        [-1.5029e-02,  1.5418e-01, -6.4943e-02,  3.4804e-02,  3.4375e-01,\n",
      "          6.0560e-02, -2.3006e-01,  4.3845e-02,  1.9074e-02, -2.3165e-02,\n",
      "          2.8959e-01, -3.5577e-01,  3.5614e-03, -1.4303e-01,  4.2133e-01,\n",
      "         -1.2109e-01,  1.0460e-01, -1.8668e-01,  1.0310e-01,  2.0639e-01,\n",
      "         -1.0321e-01,  4.1417e-02,  4.6210e-01,  3.8146e-01,  7.7100e-02],\n",
      "        [-7.7024e-02,  2.1316e-02, -4.5065e-02, -1.4509e-01, -7.1373e-02,\n",
      "         -5.4669e-02,  9.7622e-02,  1.0060e-01,  1.0299e-01, -2.1415e-01,\n",
      "          8.8961e-03, -1.4251e-01, -1.1981e-01,  8.4291e-02,  2.2555e-01,\n",
      "          8.2753e-02,  1.6957e-01,  1.4058e-01, -1.9833e-01, -1.6004e-02,\n",
      "         -7.4022e-02, -1.7383e-01, -1.0620e-01,  1.3681e-02, -2.9628e-01],\n",
      "        [-5.8364e-02,  8.5614e-02, -1.3750e-01, -2.2947e-01, -1.8601e-01,\n",
      "         -2.0935e-01, -2.3886e-01,  1.0792e-01, -1.3245e-01, -9.8697e-02,\n",
      "         -3.0702e-02,  2.7934e-01, -2.3544e-01, -4.6493e-02, -2.2628e-01,\n",
      "         -8.9115e-02, -1.4041e-02,  9.4628e-02,  1.7512e-01, -2.9581e-01,\n",
      "         -2.2641e-01,  3.1840e-01,  3.1289e-01,  2.8829e-01, -9.0479e-02],\n",
      "        [ 1.1215e-01, -3.3415e-03, -1.9552e-01,  2.7298e-01,  4.9950e-02,\n",
      "         -7.5328e-02,  1.4118e-01, -1.6153e-01, -2.3340e-01,  1.2228e-01,\n",
      "          2.4254e-01,  3.9708e-02, -1.5522e-01, -1.2645e-01, -2.1766e-02,\n",
      "         -1.1468e-01, -9.9938e-02, -1.0913e-01, -9.9176e-02,  1.5702e-01,\n",
      "         -3.9416e-01, -6.2813e-02, -1.2285e-01,  2.7167e-01, -6.0555e-02],\n",
      "        [-9.9821e-03,  2.3697e-01,  6.7430e-02,  7.1710e-03, -6.5568e-02,\n",
      "          1.2850e-01, -2.1792e-01, -9.8136e-02, -1.3657e-02, -1.4827e-01,\n",
      "          2.1282e-01,  2.1031e-01,  4.0267e-02,  1.5763e-02, -1.1878e-01,\n",
      "         -1.1700e-02,  1.1337e-01,  1.3797e-01,  7.3337e-02,  1.5934e-01,\n",
      "          1.1772e-01, -7.3549e-02, -2.2394e-01, -2.5215e-01, -4.1644e-02],\n",
      "        [-1.1517e-01, -1.8579e-01, -2.3456e-02,  3.2845e-02,  4.2607e-02,\n",
      "         -5.0134e-02, -1.9715e-02,  1.1680e-01,  1.3121e-02,  5.9445e-03,\n",
      "          1.9801e-01,  1.2369e-01,  1.1552e-01,  1.1459e-01, -4.9943e-02,\n",
      "         -2.0446e-02, -3.8584e-02,  1.5196e-01,  1.8568e-01,  2.2142e-01,\n",
      "          1.0811e-01,  1.3749e-02,  1.3548e-01,  3.6956e-02,  1.0059e-02],\n",
      "        [ 6.6090e-02, -2.2241e-01, -9.5229e-02,  1.6574e-01, -2.1203e-01,\n",
      "          2.9635e-01, -4.1787e-01, -1.3404e-01, -1.5415e-01,  1.0804e-01,\n",
      "         -4.3579e-01,  2.3215e-01,  1.4817e-01, -1.7789e-01, -4.6622e-03,\n",
      "         -2.6494e-02, -3.9969e-01, -4.3328e-02, -1.1619e-01, -2.7971e-01,\n",
      "         -3.4989e-01, -1.7614e-02, -3.7330e-01,  1.2444e-01, -9.9457e-02],\n",
      "        [-2.0265e-01,  6.4782e-02,  3.3976e-01,  7.6993e-02,  1.0224e-01,\n",
      "         -1.4419e-01, -1.2314e-01, -1.0445e-01,  4.9229e-02,  5.3221e-02,\n",
      "          2.9089e-01,  3.4033e-02,  6.7439e-02, -5.9153e-02,  1.3080e-01,\n",
      "          1.4491e-01, -2.4055e-01,  1.4809e-01, -1.0437e-01,  1.9013e-01,\n",
      "         -1.6626e-02, -2.0027e-01,  4.7152e-01,  1.4186e-01, -1.2168e-01],\n",
      "        [-7.1863e-02, -1.1384e-01,  2.2278e-02,  1.4069e-01,  1.6530e-01,\n",
      "         -1.2882e-01,  8.6198e-02, -1.4645e-01, -5.8743e-02, -1.0057e-03,\n",
      "         -1.7163e-01,  1.2048e-01,  1.0552e-01,  1.2904e-01, -4.9031e-03,\n",
      "          9.4673e-02,  1.2338e-01,  7.4458e-02, -1.2355e-02, -9.2009e-02,\n",
      "          2.6882e-02,  2.8837e-01, -3.4767e-01, -3.4791e-02, -1.8993e-01],\n",
      "        [-1.9581e-01,  2.4458e-01, -1.0421e-01,  1.3276e-01,  2.1246e-01,\n",
      "         -8.9615e-02, -2.2078e-01,  3.0893e-01, -3.5277e-02,  1.7431e-01,\n",
      "         -4.4377e-01, -4.0874e-01,  7.9254e-02,  3.5037e-02, -2.6223e-01,\n",
      "         -4.9175e-02, -3.3795e-01, -1.3919e-02,  3.1069e-01,  1.0907e-01,\n",
      "         -3.5093e-01,  7.5226e-02, -3.6208e-01, -3.4323e-01,  2.5888e-01],\n",
      "        [ 4.0346e-02,  6.0806e-02, -2.7251e-01,  2.6509e-01,  8.4619e-02,\n",
      "          1.4567e-01, -2.3627e-01,  3.4358e-01,  1.1992e-01, -4.6565e-03,\n",
      "          1.6203e-01,  9.5051e-02, -2.6405e-01, -1.4497e-01, -2.1649e-01,\n",
      "         -1.9610e-01, -1.0713e-01, -2.0007e-01,  2.3142e-01,  1.8905e-01,\n",
      "         -1.8697e-01,  3.7257e-01,  9.9284e-03,  4.5917e-01,  9.4791e-02],\n",
      "        [ 9.7705e-02, -6.8090e-02, -3.6513e-01, -2.0414e-01, -1.2794e-01,\n",
      "          7.4120e-03, -3.4083e-02,  2.2583e-01, -1.6874e-01, -5.6840e-02,\n",
      "         -2.6181e-01,  1.5950e-01,  1.4109e-01, -9.3298e-02, -3.1462e-01,\n",
      "          9.6898e-02,  6.3449e-02, -4.0322e-02, -5.1093e-02, -6.9264e-02,\n",
      "          2.6139e-01,  4.4098e-01,  1.5524e-01,  1.1623e-01, -2.5053e-01]])\n",
      "None tensor([ 0.0205,  0.1438,  0.0334, -0.1235,  0.0927, -0.0265, -0.0842,  0.0637,\n",
      "         0.1101,  0.0876, -0.1053,  0.2357,  0.0521, -0.1240,  0.1105, -0.0706,\n",
      "         0.0551, -0.1010, -0.0869, -0.0889,  0.0146,  0.1115, -0.1358, -0.0400,\n",
      "        -0.0385])\n",
      "None tensor([[-1.1644e-01,  2.3118e-01, -2.6683e-02,  1.9151e-01,  3.3047e-01,\n",
      "         -1.7617e-01,  1.1384e-01, -1.2390e-01,  2.9315e-01, -7.4269e-02,\n",
      "          1.2341e-01, -1.3459e-02, -8.3012e-02,  4.1221e-01, -9.0055e-02,\n",
      "          3.8175e-01,  1.5570e-01,  5.4776e-02,  1.4202e-02, -2.6670e-01,\n",
      "          2.1515e-01,  1.4746e-01, -1.1516e-01,  2.9928e-01,  3.4076e-01],\n",
      "        [ 1.1414e-01,  1.5296e-01, -2.0282e-01, -6.2677e-02, -8.6506e-02,\n",
      "         -2.0280e-01,  3.3639e-02, -5.7563e-02, -1.6769e-01, -1.0584e-01,\n",
      "         -2.7239e-02, -8.1638e-02, -1.2083e-01, -1.2805e-01,  2.8963e-02,\n",
      "         -1.9228e-01, -1.4537e-01, -5.5617e-02,  1.3670e-01,  1.4139e-01,\n",
      "          1.4598e-01, -1.0345e-01,  1.4467e-01, -9.0082e-02, -1.1400e-01],\n",
      "        [-1.5504e-01,  9.7653e-02,  1.0983e-01,  1.8528e-01,  1.9222e-01,\n",
      "          9.5787e-02,  1.0809e-01, -3.2086e-01,  8.0398e-02, -1.9764e-01,\n",
      "          3.0263e-01, -1.0139e-02,  1.7673e-01,  5.6115e-01,  5.5583e-02,\n",
      "          1.8676e-01,  2.7985e-01, -3.3053e-02,  1.6033e-01, -1.7473e-01,\n",
      "         -3.3392e-02, -1.2367e-01, -3.3797e-01,  5.6399e-01,  2.4914e-01],\n",
      "        [ 1.5374e-01,  1.9034e-01,  1.4203e-01,  1.7243e-01,  2.7305e-01,\n",
      "         -1.1061e-02,  1.2346e-01, -1.2784e-01,  3.6097e-01, -1.5223e-02,\n",
      "          1.5413e-01,  2.4940e-01,  2.1278e-01,  2.5982e-01, -1.3231e-01,\n",
      "          2.9383e-01,  1.8364e-01, -1.9433e-01,  4.5636e-02, -3.0127e-01,\n",
      "          2.3079e-01, -2.2163e-01, -2.7440e-01,  3.9328e-01,  1.1454e-02],\n",
      "        [ 1.6255e-01,  1.6407e-01, -2.1875e-02,  2.0703e-01,  5.4958e-01,\n",
      "          2.9645e-02,  3.4810e-01, -2.0709e-01,  3.7966e-01, -2.5904e-01,\n",
      "          2.1046e-01,  2.7954e-01,  3.0567e-01,  4.6974e-01, -4.1023e-02,\n",
      "          2.6142e-01,  1.2297e-01, -2.8971e-02, -1.2289e-01, -2.1820e-01,\n",
      "          6.4895e-02,  2.4228e-03, -2.9577e-01,  7.5278e-01,  7.7601e-02],\n",
      "        [ 1.9460e-01, -6.9881e-02, -4.1566e-02,  7.0977e-03, -1.4289e-01,\n",
      "          1.5340e-01,  4.8328e-02,  2.2264e-01, -2.6776e-01,  1.7691e-01,\n",
      "         -2.6474e-01,  1.6355e-03, -4.2847e-02, -2.6494e-01,  2.5000e-01,\n",
      "         -8.0162e-02, -2.6960e-01,  1.3571e-02,  2.5024e-01,  1.3458e-01,\n",
      "         -2.9651e-01,  2.4190e-01,  4.1572e-01, -3.0072e-01, -3.5931e-01],\n",
      "        [-3.9748e-02,  3.4756e-01,  3.2141e-02,  2.8831e-01,  6.3692e-01,\n",
      "          4.5094e-02,  9.4264e-02, -2.8765e-01,  1.6950e-01, -2.0606e-01,\n",
      "          1.7582e-01,  7.1634e-02,  4.8776e-02,  4.5509e-01, -7.0687e-02,\n",
      "          3.0398e-01,  2.4597e-01,  1.9479e-01, -2.6061e-02, -2.7616e-01,\n",
      "          3.3703e-01,  1.3945e-01, -2.1998e-01,  6.0206e-01,  2.4523e-01],\n",
      "        [-1.4271e-01,  1.0576e-01, -1.2201e-01, -4.5656e-02, -3.5319e-02,\n",
      "         -2.2099e-01, -3.8412e-02,  3.5921e-01, -1.8815e-01,  1.1700e-01,\n",
      "          1.1912e-01, -1.9737e-02,  1.3385e-01,  2.7986e-02, -4.1215e-03,\n",
      "         -9.3374e-02, -3.6294e-01,  2.1581e-01, -9.5425e-02,  3.9873e-01,\n",
      "         -3.4686e-01,  8.6823e-02, -3.6645e-01, -1.8370e-01, -2.3781e-01],\n",
      "        [ 2.4421e-02,  3.3420e-02,  7.5626e-02, -1.2672e-01, -2.3000e-01,\n",
      "         -4.8866e-05, -3.1237e-01,  3.4267e-01, -2.0440e-01,  4.3278e-01,\n",
      "         -2.0445e-01,  2.7313e-01, -4.6634e-02, -3.5224e-01,  8.8752e-03,\n",
      "         -2.4140e-01, -3.4785e-01,  3.1365e-02,  1.4978e-01,  4.6281e-01,\n",
      "          1.6165e-03,  3.3577e-01,  5.5398e-01, -3.6618e-01,  1.5084e-03],\n",
      "        [ 9.3146e-02, -1.6733e-01, -1.8371e-02, -1.5719e-01, -1.3947e-01,\n",
      "         -5.4758e-02, -1.3104e-01, -1.9664e-01,  5.3596e-02, -1.4733e-01,\n",
      "          1.3097e-01,  9.1253e-02, -1.9137e-01,  1.2715e-01,  8.7464e-03,\n",
      "          5.3723e-02, -1.8768e-01,  1.2380e-01, -6.2231e-02, -3.7226e-02,\n",
      "         -1.2188e-01, -7.3274e-02,  1.8764e-01,  7.6155e-03, -2.8694e-02],\n",
      "        [ 2.0323e-01,  2.1536e-01, -1.9599e-02,  3.6458e-01,  4.1863e-01,\n",
      "          1.4824e-02,  1.9763e-01, -3.6095e-02,  1.1811e-01, -8.9459e-02,\n",
      "          8.6408e-02,  2.6159e-01,  1.9756e-01,  2.2691e-01,  3.7801e-03,\n",
      "          4.3226e-01, -9.6753e-03,  2.5400e-02,  1.4827e-01, -2.8340e-01,\n",
      "          1.2759e-01, -5.5052e-02, -1.9741e-01,  5.4628e-01,  4.1036e-02],\n",
      "        [-3.8331e-02,  9.3578e-02,  1.2720e-01,  3.8249e-01,  4.7178e-01,\n",
      "          1.2353e-01,  4.2232e-01, -1.2663e-01,  4.6826e-01, -2.3630e-01,\n",
      "          1.3268e-01,  3.3941e-01,  3.7008e-02,  5.9368e-01, -1.4137e-01,\n",
      "          2.2266e-01,  3.8313e-01,  1.8803e-01, -8.5513e-02, -3.5573e-01,\n",
      "          1.0114e-01, -1.3106e-01, -3.7873e-01,  5.7881e-01,  2.4371e-01],\n",
      "        [ 1.5293e-01,  1.0614e-01,  1.8080e-01,  2.9304e-01,  4.0035e-01,\n",
      "          1.3174e-02,  2.7282e-01, -1.9459e-01,  9.7997e-02, -3.0936e-02,\n",
      "          3.0335e-01, -1.0994e-02,  2.5171e-01,  5.0267e-01,  3.0251e-02,\n",
      "          2.6255e-01,  9.8783e-03,  3.1806e-02,  5.1914e-02, -2.4164e-01,\n",
      "          1.1837e-01, -8.0167e-02, -2.6480e-01,  3.3066e-01,  1.3221e-02],\n",
      "        [ 1.6220e-01,  5.4061e-02,  2.0796e-01,  1.3094e-01,  1.2145e-01,\n",
      "          3.4389e-02,  2.0110e-02, -8.7403e-02,  4.5671e-02, -1.0697e-01,\n",
      "          2.0278e-01,  1.0585e-01,  1.7849e-03,  4.0792e-01,  1.4605e-01,\n",
      "          2.4640e-01, -4.1981e-02,  3.4047e-02, -5.9737e-02, -8.5019e-02,\n",
      "          4.1082e-03,  3.3284e-02, -1.5412e-01,  4.2505e-01,  1.3229e-01],\n",
      "        [ 6.8020e-02,  2.9987e-01,  8.9527e-03,  2.0280e-01,  5.8724e-01,\n",
      "          7.0497e-02,  2.9623e-01, -1.3639e-01,  3.8305e-01, -1.4377e-01,\n",
      "          1.4849e-01,  9.9652e-02,  5.7254e-02,  8.4437e-01,  1.8813e-02,\n",
      "          3.7184e-01,  9.6659e-02, -3.2909e-02,  6.9213e-02, -2.3424e-01,\n",
      "          1.5214e-01, -3.7336e-02, -2.9411e-01,  5.3003e-01,  2.6767e-01],\n",
      "        [-2.7983e-01, -1.3072e-01, -4.7880e-03,  3.4005e-01,  6.8637e-01,\n",
      "          6.9083e-02,  2.1392e-02, -2.8432e-01,  3.6306e-01,  1.7145e-01,\n",
      "          2.4005e-01,  3.0196e-01, -2.3646e-01,  7.6590e-01, -4.6285e-02,\n",
      "          3.5723e-01,  2.1816e-01,  1.7348e-02,  1.6706e-01, -3.6333e-01,\n",
      "          4.4861e-01, -1.1312e-01, -3.6757e-01,  3.8495e-01, -1.8057e-01],\n",
      "        [ 1.4277e-01,  3.0554e-01,  2.0041e-01,  1.1491e-01,  4.5208e-01,\n",
      "          1.1725e-01,  3.2728e-01, -3.0090e-01,  7.3535e-02, -1.9922e-01,\n",
      "          3.0407e-01,  2.2859e-01,  5.4592e-02,  5.9979e-01, -8.6571e-02,\n",
      "          2.3984e-01,  3.7353e-01, -2.3185e-02,  6.2718e-02, -2.0856e-01,\n",
      "          2.9279e-01, -5.9968e-02, -3.0946e-01,  5.5303e-01,  4.4031e-02],\n",
      "        [ 1.2999e-02,  1.3626e-01,  1.2853e-01,  3.7870e-01,  5.7073e-01,\n",
      "          9.6141e-02,  2.4180e-01, -1.6143e-01,  4.1487e-01, -2.4199e-01,\n",
      "          3.8758e-01,  6.1175e-02,  3.1664e-01,  6.5235e-01, -1.4109e-01,\n",
      "          2.5851e-01,  4.6034e-01,  2.4915e-01, -1.3627e-01, -2.8339e-01,\n",
      "          3.5928e-01, -1.4963e-01, -2.7418e-01,  4.7478e-01,  1.9852e-01],\n",
      "        [ 4.9983e-02,  2.9133e-01,  2.1228e-01,  2.3534e-01,  4.6241e-01,\n",
      "          1.2304e-01,  2.1895e-01, -2.5231e-01,  2.7314e-01, -1.9745e-01,\n",
      "          1.5010e-01,  1.7359e-01,  1.4899e-01,  5.8545e-01, -2.2812e-01,\n",
      "          2.8177e-01,  3.5420e-01, -1.1188e-01, -2.0257e-01, -1.1215e-01,\n",
      "          3.2978e-01, -9.1035e-03, -2.5104e-01,  2.9659e-01,  1.2302e-01],\n",
      "        [ 9.3970e-02,  5.4304e-02,  2.1177e-03,  1.5669e-01,  2.9662e-01,\n",
      "         -4.3377e-02,  2.5675e-01, -3.2446e-01,  3.2751e-01, -3.2418e-01,\n",
      "          6.6097e-03,  3.4225e-01,  1.5629e-01,  5.5509e-01,  1.6247e-01,\n",
      "          4.3164e-01,  3.0832e-01, -1.4309e-01, -2.4300e-02,  2.0889e-03,\n",
      "          1.4808e-02,  1.5828e-01, -1.8404e-01,  6.2570e-01,  3.8121e-01],\n",
      "        [ 4.1787e-02,  4.7474e-02,  1.8319e-01, -1.3287e-01, -1.8870e-01,\n",
      "          1.7005e-01, -1.6227e-01,  4.2695e-01, -3.8282e-02,  3.7018e-01,\n",
      "         -6.2102e-02, -4.0492e-02, -1.5422e-01, -3.0759e-01,  1.8259e-01,\n",
      "         -2.2656e-01, -1.7488e-01, -3.0519e-02, -7.6541e-02,  1.4662e-01,\n",
      "          2.7374e-03,  9.8550e-02,  1.8161e-01, -4.7692e-01,  6.6082e-02],\n",
      "        [ 1.0587e-01, -7.1112e-02,  6.0830e-02,  1.2820e-02,  3.4902e-02,\n",
      "         -1.7323e-02,  2.0862e-02,  1.7299e-02,  2.8375e-02,  1.7453e-01,\n",
      "          3.8677e-03,  1.2140e-01,  1.4072e-01, -7.7265e-02,  1.6365e-02,\n",
      "         -5.7762e-02,  1.3729e-02, -6.4789e-02,  9.7968e-02,  7.6604e-02,\n",
      "          3.2553e-02, -2.4859e-03,  3.1146e-01,  2.9267e-02,  5.3057e-02],\n",
      "        [ 4.1239e-02, -9.8500e-02, -8.4061e-02,  3.7795e-03, -1.7709e-01,\n",
      "         -1.7067e-01,  4.1212e-02,  1.7137e-01,  1.2323e-01, -8.7340e-02,\n",
      "         -1.7535e-01, -7.9898e-02, -1.5103e-01,  1.4798e-01, -1.9658e-01,\n",
      "         -1.4072e-02, -4.1180e-02,  3.3036e-02,  9.8626e-02, -1.6813e-01,\n",
      "          6.9253e-03,  9.1314e-02, -1.5011e-01, -1.2827e-01, -9.4641e-02],\n",
      "        [-1.4581e-01,  2.2789e-01,  2.1041e-01,  2.4174e-01,  4.9394e-01,\n",
      "         -1.1384e-01,  7.5808e-02, -1.6789e-01,  4.0705e-01, -1.5242e-01,\n",
      "          8.3146e-02,  2.3477e-01, -1.9175e-02,  3.0511e-01, -7.2570e-02,\n",
      "          3.3274e-01,  3.2045e-01,  1.6419e-01,  1.0887e-01, -2.2994e-01,\n",
      "          1.4814e-01, -1.2838e-01, -3.0423e-01,  5.4149e-01,  3.6891e-01],\n",
      "        [ 1.6655e-01,  9.2041e-02,  6.3517e-02,  1.0023e-01,  3.9972e-01,\n",
      "          1.0826e-01,  3.0026e-01, -3.5621e-01,  1.8325e-01, -1.3643e-01,\n",
      "          5.9662e-02,  2.8810e-01,  9.8369e-02,  4.3946e-01, -1.3101e-01,\n",
      "          2.0961e-01,  8.6261e-02,  1.6236e-01,  1.5699e-01, -2.6137e-01,\n",
      "          3.2875e-01, -6.4947e-03, -3.5342e-01,  3.7968e-01,  3.3036e-01]])\n",
      "None tensor([ 0.1216, -0.1780,  0.1002,  0.1311,  0.0319,  0.2743, -0.0359,  0.1653,\n",
      "         0.1807, -0.1965, -0.0792,  0.0022,  0.0144,  0.0009, -0.1097, -0.0313,\n",
      "         0.0418, -0.0241,  0.1306, -0.0090,  0.0566, -0.2136, -0.2164,  0.1371,\n",
      "         0.0198])\n",
      "None tensor([[ 0.2086, -0.1586,  0.1712,  0.1990,  0.4951, -0.2947,  0.2472, -0.3472,\n",
      "         -0.4721, -0.1467,  0.2225,  0.6174,  0.2781,  0.1421,  0.6482,  0.4275,\n",
      "          0.3503,  0.4680, -0.0119,  0.1213, -0.2875, -0.2169,  0.1018,  0.2160,\n",
      "          0.2418],\n",
      "        [-0.0899, -0.1531, -0.2437, -0.1290, -0.5589,  0.1079, -0.2368,  0.2779,\n",
      "          0.2755, -0.0078, -0.2266, -0.7431, -0.1100,  0.0886, -0.4668, -0.4879,\n",
      "         -0.3101, -0.6880, -0.2812, -0.2897,  0.1700,  0.1490,  0.1088, -0.1225,\n",
      "         -0.2908]])\n",
      "None tensor([-0.0996,  0.0883])\n"
     ]
    }
   ],
   "source": [
    "for p in ps_model.network.parameters():\n",
    "    if p.requires_grad:\n",
    "         print(p.name, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(treated_ps_list, control_ps_list, bins1):\n",
    "    pyplot.hist(treated_ps_list, bins1, alpha=0.5, label='treated')\n",
    "    pyplot.hist(control_ps_list, bins1, alpha=0.5, label='control')\n",
    "\n",
    "    pyplot.legend(loc='upper right')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 110\n"
     ]
    }
   ],
   "source": [
    "ps_matched_control_list = tuple_matched_control[1].tolist()\n",
    "ps_un_matched_control_list = tuple_unmatched_control[1].tolist()\n",
    "ps_treated_list = tuple_treated[1].tolist()\n",
    "\n",
    "print(len(ps_matched_control_list), len(ps_treated_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins1 = np.linspace(0, 1, 100)\n",
    "bins2 = np.linspace(0, 0.2, 100)\n",
    "bins3 = np.linspace(0.2, 0.5, 100)\n",
    "bins4 = np.linspace(0.5, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matched control and treated\n",
    "draw(ps_treated_list, ps_matched_control_list, bins1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# unmatched control and treated\n",
    "draw(ps_treated_list, ps_un_matched_control_list, bins1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "from GAN import Generator, Discriminator\n",
    "from Utils import Utils\n",
    "\n",
    "\n",
    "class GAN_Module:\n",
    "    def __init__(self, discriminator_in_nodes, generator_out_nodes, ps_model, device):\n",
    "        self.discriminator = Discriminator(in_nodes=discriminator_in_nodes).to(device)\n",
    "        self.discriminator.apply(self.__weights_init)\n",
    "\n",
    "        self.generator = Generator(out_nodes=generator_out_nodes).to(device)\n",
    "        self.generator.apply(self.__weights_init)\n",
    "\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.ps_model = ps_model\n",
    "\n",
    "    def get_generator(self):\n",
    "        return self.generator\n",
    "\n",
    "    def train_GAN(self, train_parameters, device):\n",
    "        epochs = train_parameters[\"epochs\"]\n",
    "        train_set = train_parameters[\"train_set\"]\n",
    "        lr = train_parameters[\"lr\"]\n",
    "        shuffle = train_parameters[\"shuffle\"]\n",
    "        batch_size = train_parameters[\"batch_size\"]\n",
    "        BETA = train_parameters[\"BETA\"]\n",
    "\n",
    "        data_loader_train = torch.utils.data.DataLoader(train_set,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=shuffle)\n",
    "\n",
    "        g_optimizer = optim.Adam(self.generator.parameters(), lr=lr)\n",
    "        d_optimizer = optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch += 1\n",
    "\n",
    "            total_G_loss = 0\n",
    "            total_D_loss = 0\n",
    "            total_prop_loss = 0\n",
    "            total_d_pred_real = 0\n",
    "            total_d_pred_fake = 0\n",
    "\n",
    "            for batch in data_loader_train:\n",
    "                covariates_X_control, ps_score_control, y_f, y_cf = batch\n",
    "                covariates_X_control = covariates_X_control.to(device)\n",
    "                covariates_X_control_size = covariates_X_control.size(0)\n",
    "                ps_score_control = ps_score_control.squeeze().to(device)\n",
    "\n",
    "                # 1. Train Discriminator\n",
    "                real_data = covariates_X_control\n",
    "\n",
    "                # Generate fake data\n",
    "                fake_data = self.generator(self.__noise(covariates_X_control_size)).detach()\n",
    "                # Train D\n",
    "                d_error, d_pred_real, d_pred_fake = self.__train_discriminator(d_optimizer,\n",
    "                                                                               real_data, fake_data)\n",
    "                total_D_loss += d_error\n",
    "                total_d_pred_real += d_pred_real\n",
    "                total_d_pred_fake += d_pred_fake\n",
    "\n",
    "                # 2. Train Generator\n",
    "                # Generate fake data\n",
    "                fake_data = self.generator(self.__noise(covariates_X_control_size))\n",
    "                # Train G\n",
    "                error_g, prop_loss = self.__train_generator(g_optimizer, fake_data, BETA, ps_score_control,\n",
    "                                                            device)\n",
    "                total_G_loss += error_g\n",
    "                total_prop_loss += prop_loss\n",
    "\n",
    "            if epoch % 1000 == 0:\n",
    "                print(\"Epoch: {0}, D_loss: {1}, D_score_real: {2}, D_score_Fake: {3}, G_loss: {4}, \"\n",
    "                      \"Prop_loss: {5}\"\n",
    "                      .format(epoch,\n",
    "                              total_D_loss, total_d_pred_real, total_d_pred_fake, total_G_loss, total_prop_loss))\n",
    "\n",
    "    def eval_GAN(self, eval_size, device):\n",
    "        treated_g = self.generator(self.__noise(eval_size))\n",
    "        ps_score_list_treated = self.__get_propensity_score(treated_g, device)\n",
    "        return treated_g, ps_score_list_treated\n",
    "\n",
    "    def __cal_propensity_loss(self, ps_score_control,\n",
    "                              gen_treated, device):\n",
    "        ps_score_list_treated = self.__get_propensity_score(gen_treated, device)\n",
    "\n",
    "        ps_score_treated = torch.tensor(ps_score_list_treated).to(device)\n",
    "        ps_score_control = ps_score_control.to(device)\n",
    "        prop_loss = torch.sum((torch.sub(ps_score_treated.float(),\n",
    "                                         ps_score_control.float())) ** 2)\n",
    "        return prop_loss\n",
    "\n",
    "    def __get_propensity_score(self, gen_treated, device):\n",
    "        # Assign Treated\n",
    "        Y = np.ones(gen_treated.size(0))\n",
    "        eval_set = Utils.convert_to_tensor(gen_treated.cpu().detach().numpy(), Y)\n",
    "        ps_eval_parameters_NN = {\n",
    "            \"eval_set\": eval_set\n",
    "        }\n",
    "        ps_score_list_treated = self.ps_model.eval(ps_eval_parameters_NN, device,\n",
    "                                                   eval_from_GAN=True)\n",
    "        return ps_score_list_treated\n",
    "\n",
    "    @staticmethod\n",
    "    def __noise(_size):\n",
    "        n = Variable(torch.normal(mean=0, std=1, size=(_size, 25)))\n",
    "        # print(n.size())\n",
    "        if torch.cuda.is_available(): return n.cuda()\n",
    "        return n\n",
    "\n",
    "    @staticmethod\n",
    "    def __weights_init(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "    @staticmethod\n",
    "    def __real_data_target(size):\n",
    "        data = Variable(torch.ones(size, 1))\n",
    "        if torch.cuda.is_available(): return data.cuda()\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def __fake_data_target(size):\n",
    "        data = Variable(torch.zeros(size, 1))\n",
    "        if torch.cuda.is_available(): return data.cuda()\n",
    "        return data\n",
    "\n",
    "    def __train_discriminator(self, optimizer, real_data, fake_data):\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1.1 Train on Real Data\n",
    "        prediction_real = self.discriminator(real_data)\n",
    "        real_score = torch.mean(prediction_real).item()\n",
    "\n",
    "        # Calculate error and back propagate\n",
    "        error_real = self.loss(prediction_real, self.__real_data_target(real_data.size(0)))\n",
    "        error_real.backward()\n",
    "\n",
    "        # 1.2 Train on Fake Data\n",
    "        prediction_fake = self.discriminator(fake_data)\n",
    "        fake_score = torch.mean(prediction_fake).item()\n",
    "        # Calculate error and backpropagate\n",
    "        error_fake = self.loss(prediction_fake, self.__fake_data_target(real_data.size(0)))\n",
    "        error_fake.backward()\n",
    "\n",
    "        # 1.3 Update weights with gradients\n",
    "        optimizer.step()\n",
    "        loss_D = error_real + error_fake\n",
    "        # Return error\n",
    "        return loss_D.item(), real_score, fake_score\n",
    "\n",
    "    def __train_generator(self, optimizer, fake_data, BETA, ps_score_control,\n",
    "                          device):\n",
    "        # 2. Train Generator\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Sample noise and generate fake data\n",
    "        predicted_D = self.discriminator(fake_data)\n",
    "        # Calculate error and back propagate\n",
    "        ps_score_control = ps_score_control.to(device)\n",
    "        fake_data = fake_data.to(device)\n",
    "        error_g = self.loss(predicted_D, self.__real_data_target(predicted_D.size(0)))\n",
    "        prop_loss = self.__cal_propensity_loss(ps_score_control,\n",
    "                                               fake_data, device)\n",
    "        error = error_g + (BETA * prop_loss)\n",
    "        error.backward()\n",
    "        # Update weights with gradients\n",
    "        optimizer.step()\n",
    "        # Return error\n",
    "        return error_g.item(), prop_loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Constants.GAN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, D_loss: 6.484352111816406, D_score_real: 4.753779768943787, D_score_Fake: 2.244253993034363, G_loss: 8.261410355567932, Prop_loss: 84.21545600891113\n",
      "Epoch: 2000, D_loss: 6.237849414348602, D_score_real: 4.846515357494354, D_score_Fake: 2.209312289953232, G_loss: 8.409345030784607, Prop_loss: 22.815560579299927\n",
      "Epoch: 3000, D_loss: 5.379218220710754, D_score_real: 5.202274680137634, D_score_Fake: 1.7526859790086746, G_loss: 9.912554264068604, Prop_loss: 17.027713894844055\n",
      "Epoch: 4000, D_loss: 4.714742660522461, D_score_real: 5.47422581911087, D_score_Fake: 1.536693200469017, G_loss: 10.902239441871643, Prop_loss: 51.16793727874756\n",
      "Epoch: 5000, D_loss: 4.323586106300354, D_score_real: 5.580657243728638, D_score_Fake: 1.570993259549141, G_loss: 10.773802042007446, Prop_loss: 32.96702814102173\n",
      "Epoch: 6000, D_loss: 4.604784965515137, D_score_real: 5.662094533443451, D_score_Fake: 1.5359097868204117, G_loss: 12.217398405075073, Prop_loss: 43.44487428665161\n",
      "Epoch: 7000, D_loss: 4.234043270349503, D_score_real: 5.577366828918457, D_score_Fake: 1.2061744630336761, G_loss: 13.379080414772034, Prop_loss: 7.570726692676544\n",
      "Epoch: 8000, D_loss: 3.96755313873291, D_score_real: 5.732943475246429, D_score_Fake: 1.2279018461704254, G_loss: 13.257057309150696, Prop_loss: 9.086600303649902\n",
      "Epoch: 9000, D_loss: 3.860927402973175, D_score_real: 5.7480690479278564, D_score_Fake: 1.153217390179634, G_loss: 13.306794881820679, Prop_loss: 92.03190803527832\n",
      "Epoch: 10000, D_loss: 4.082196295261383, D_score_real: 6.03668212890625, D_score_Fake: 1.1763522624969482, G_loss: 14.674713969230652, Prop_loss: 17.92044997215271\n"
     ]
    }
   ],
   "source": [
    "# GAN Part from here\n",
    "GAN_train_parameters = {\n",
    "            \"epochs\": Constants.GAN_EPOCHS,\n",
    "            \"lr\": Constants.GAN_LR,\n",
    "            \"shuffle\": True,\n",
    "            \"train_set\": tensor_unmatched_control,\n",
    "            \"batch_size\": Constants.GAN_BATCH_SIZE,\n",
    "            \"BETA\": Constants.GAN_BETA\n",
    "        }\n",
    "\n",
    "gan = GAN_Module(Constants.GAN_DISCRIMINATOR_IN_NODES,\n",
    "                          Constants.GAN_GENERATOR_OUT_NODES,\n",
    "                          ps_model, device)\n",
    "gan.train_GAN(GAN_train_parameters, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None tensor([[ 6.5097e-04, -1.7002e-02, -3.0651e-01, -1.6960e-01, -1.8312e-01,\n",
      "         -1.4993e-01, -1.4131e-01,  7.5601e-02,  1.0128e-02, -5.9462e-02,\n",
      "          5.5825e-02,  3.9940e-02,  2.2372e-01, -4.0432e-02, -3.8436e-02,\n",
      "         -8.0285e-02,  3.7613e-02, -1.5925e-01, -1.8394e-01,  2.2996e-01,\n",
      "          1.5143e-01,  1.7001e-01,  2.2519e-01, -2.9983e-02, -6.2041e-02],\n",
      "        [ 8.3384e-02, -3.6643e-02, -3.3339e-01, -7.2526e-02,  2.1678e-01,\n",
      "         -1.0436e-01,  2.1112e-01, -2.6544e-01,  4.5422e-02,  4.9079e-02,\n",
      "         -2.8169e-01,  9.1486e-03, -1.9106e-01, -4.2072e-02, -1.3664e-01,\n",
      "          4.4773e-02,  6.8548e-02, -2.1993e-02, -1.7416e-01,  4.4245e-02,\n",
      "          1.2394e-01,  3.3318e-01,  3.1456e-01,  1.4697e-01, -2.5896e-01],\n",
      "        [ 6.2710e-03, -3.5689e-03,  3.9943e-02,  1.9882e-01,  1.0505e-01,\n",
      "          2.5068e-02,  2.9301e-02, -1.0379e-01, -1.8220e-01, -1.8106e-01,\n",
      "          1.0037e-01,  4.5255e-02, -2.9388e-01,  4.1484e-02,  5.3230e-02,\n",
      "          1.6032e-01, -1.1235e-01,  1.0805e-02,  2.4644e-01,  1.9559e-02,\n",
      "         -1.4402e-01,  1.8607e-01,  1.1136e-01,  1.4614e-01, -7.8670e-05],\n",
      "        [ 6.6255e-02,  2.2266e-02,  2.8825e-01,  5.5031e-02, -6.6849e-02,\n",
      "          1.4255e-01, -2.6789e-01,  7.6358e-03,  5.4610e-02, -3.2082e-02,\n",
      "          1.2095e-01,  1.8891e-01, -2.7715e-01, -1.0676e-01, -3.8018e-02,\n",
      "          1.2167e-01, -4.6632e-02,  6.0981e-02,  2.5891e-01,  3.4212e-01,\n",
      "          2.3353e-01,  1.2758e-01, -1.1239e-01,  9.0092e-03, -1.6333e-02],\n",
      "        [-6.9909e-02, -1.3890e-01, -1.3909e-01, -1.4620e-01, -1.1312e-01,\n",
      "          1.0727e-01,  1.7131e-01,  3.2599e-01,  4.0278e-02,  2.9481e-01,\n",
      "         -8.4775e-02,  5.8921e-02,  2.5423e-01, -1.9684e-01,  2.6455e-01,\n",
      "         -4.6124e-02, -6.2781e-02, -2.6921e-01, -2.3445e-02,  7.3132e-02,\n",
      "          4.1609e-02, -8.0921e-02,  1.1365e-01, -2.9043e-02,  1.3955e-01],\n",
      "        [-1.0116e-01,  2.8450e-02, -7.2376e-02, -5.7782e-02,  1.1536e-01,\n",
      "          1.2387e-01,  1.3766e-01, -1.6177e-01,  2.0750e-01,  1.7089e-01,\n",
      "         -1.2042e-01,  1.7359e-01,  1.3870e-01,  5.9653e-02,  1.8276e-01,\n",
      "          2.3206e-01, -1.3979e-01,  5.5347e-02, -1.0800e-01,  3.3106e-01,\n",
      "         -1.3707e-02,  1.2245e-01,  1.2965e-01,  1.9647e-01,  1.6987e-01],\n",
      "        [-6.1220e-02, -2.5249e-01, -1.0193e-01,  1.9158e-01,  1.3015e-01,\n",
      "         -5.4985e-02,  2.5865e-01, -2.1867e-01, -3.0881e-01,  3.6855e-01,\n",
      "          2.3417e-01, -2.4388e-02, -1.6807e-01, -1.6482e-01,  2.6145e-01,\n",
      "          9.4210e-03,  9.0027e-02,  4.8369e-02,  5.6364e-02,  2.8081e-01,\n",
      "         -2.9827e-01,  1.0607e-01,  2.7785e-01,  3.7268e-02,  4.2498e-02],\n",
      "        [-8.6312e-02, -5.2000e-02, -6.7352e-02, -5.1679e-02, -1.5454e-01,\n",
      "          5.0463e-02, -3.8606e-01, -6.1476e-01, -4.5743e-01,  1.7236e-01,\n",
      "          5.4499e-03,  2.7346e-01,  4.5385e-02, -7.4468e-02,  1.2071e-01,\n",
      "          5.1901e-02,  2.7355e-01,  1.6524e-01, -8.8243e-02, -2.8966e-01,\n",
      "         -1.6026e-02, -2.5212e-01, -4.2129e-01, -2.4550e-01,  1.1258e-01],\n",
      "        [-3.0892e-02, -1.2110e-02, -1.1833e-03, -1.9209e-03,  5.6092e-02,\n",
      "         -4.0914e-03, -1.7272e-01,  1.1857e-01, -2.0219e-01, -3.2226e-01,\n",
      "          7.8877e-02,  1.5409e-01,  1.1931e-01,  2.2026e-02,  8.8707e-02,\n",
      "         -1.3182e-01,  1.4185e-01, -5.5352e-02,  3.3209e-01,  1.7154e-02,\n",
      "         -1.9238e-01,  5.3076e-02,  4.0580e-01,  3.8435e-02, -3.6967e-01],\n",
      "        [ 5.6061e-02,  8.6996e-02, -8.8876e-02,  2.0114e-01, -5.4509e-03,\n",
      "          7.4715e-02,  2.0000e-01, -2.0761e-03,  2.0784e-01,  1.2720e-03,\n",
      "          1.9948e-01, -1.2561e-01,  1.6994e-02, -1.9743e-01, -3.8135e-03,\n",
      "          6.5204e-02, -9.1889e-02,  1.1637e-01, -1.0039e-01, -5.9431e-01,\n",
      "          5.4473e-02,  1.9889e-02,  2.1814e-01,  2.8995e-01, -1.4887e-01],\n",
      "        [ 1.3972e-01,  1.1067e-01,  1.6157e-01,  5.6214e-02,  1.6549e-01,\n",
      "         -1.6004e-01,  4.6795e-02, -2.1860e-01, -4.0691e-02, -5.4910e-02,\n",
      "          5.8114e-02,  8.7438e-02, -1.7342e-01,  2.4655e-02, -6.5601e-02,\n",
      "          2.0160e-01,  2.3381e-01, -1.8219e-01, -1.3385e-01, -2.0386e-03,\n",
      "          1.3044e-01,  7.2371e-02,  2.3052e-01,  4.8982e-02, -1.4803e-01],\n",
      "        [-7.0423e-02,  2.4590e-02,  3.0547e-01,  1.1566e-01, -1.7699e-02,\n",
      "         -1.2647e-01, -1.5640e-01,  2.3379e-01, -4.8408e-03,  8.2627e-02,\n",
      "         -1.2881e-01,  2.4913e-01, -2.5233e-01, -9.6157e-02,  2.5891e-01,\n",
      "          1.1867e-02, -1.0779e-01,  9.8696e-02,  2.3675e-02,  3.8278e-01,\n",
      "          1.1848e-01,  1.8344e-01,  2.6035e-01,  2.8126e-01, -2.5489e-01],\n",
      "        [-4.6335e-02,  4.3683e-02, -9.8759e-02,  4.1059e-02,  1.3826e-01,\n",
      "         -9.1813e-02, -1.2273e-01, -4.0107e-02, -1.9695e-01,  1.5609e-01,\n",
      "          4.5581e-02, -8.5099e-03,  9.3590e-02, -1.7974e-01, -1.1476e-01,\n",
      "          3.6034e-02,  9.4547e-02,  1.3885e-01, -1.4426e-01,  2.7791e-01,\n",
      "          9.4792e-03,  4.2069e-01,  2.8669e-01,  3.6373e-02, -1.6531e-01],\n",
      "        [-1.5029e-02,  1.5418e-01, -6.4943e-02,  3.4804e-02,  3.4375e-01,\n",
      "          6.0560e-02, -2.3006e-01,  4.3845e-02,  1.9074e-02, -2.3165e-02,\n",
      "          2.8959e-01, -3.5577e-01,  3.5614e-03, -1.4303e-01,  4.2133e-01,\n",
      "         -1.2109e-01,  1.0460e-01, -1.8668e-01,  1.0310e-01,  2.0639e-01,\n",
      "         -1.0321e-01,  4.1417e-02,  4.6210e-01,  3.8146e-01,  7.7100e-02],\n",
      "        [-7.7024e-02,  2.1316e-02, -4.5065e-02, -1.4509e-01, -7.1373e-02,\n",
      "         -5.4669e-02,  9.7622e-02,  1.0060e-01,  1.0299e-01, -2.1415e-01,\n",
      "          8.8961e-03, -1.4251e-01, -1.1981e-01,  8.4291e-02,  2.2555e-01,\n",
      "          8.2753e-02,  1.6957e-01,  1.4058e-01, -1.9833e-01, -1.6004e-02,\n",
      "         -7.4022e-02, -1.7383e-01, -1.0620e-01,  1.3681e-02, -2.9628e-01],\n",
      "        [-5.8364e-02,  8.5614e-02, -1.3750e-01, -2.2947e-01, -1.8601e-01,\n",
      "         -2.0935e-01, -2.3886e-01,  1.0792e-01, -1.3245e-01, -9.8697e-02,\n",
      "         -3.0702e-02,  2.7934e-01, -2.3544e-01, -4.6493e-02, -2.2628e-01,\n",
      "         -8.9115e-02, -1.4041e-02,  9.4628e-02,  1.7512e-01, -2.9581e-01,\n",
      "         -2.2641e-01,  3.1840e-01,  3.1289e-01,  2.8829e-01, -9.0479e-02],\n",
      "        [ 1.1215e-01, -3.3415e-03, -1.9552e-01,  2.7298e-01,  4.9950e-02,\n",
      "         -7.5328e-02,  1.4118e-01, -1.6153e-01, -2.3340e-01,  1.2228e-01,\n",
      "          2.4254e-01,  3.9708e-02, -1.5522e-01, -1.2645e-01, -2.1766e-02,\n",
      "         -1.1468e-01, -9.9938e-02, -1.0913e-01, -9.9176e-02,  1.5702e-01,\n",
      "         -3.9416e-01, -6.2813e-02, -1.2285e-01,  2.7167e-01, -6.0555e-02],\n",
      "        [-9.9821e-03,  2.3697e-01,  6.7430e-02,  7.1710e-03, -6.5568e-02,\n",
      "          1.2850e-01, -2.1792e-01, -9.8136e-02, -1.3657e-02, -1.4827e-01,\n",
      "          2.1282e-01,  2.1031e-01,  4.0267e-02,  1.5763e-02, -1.1878e-01,\n",
      "         -1.1700e-02,  1.1337e-01,  1.3797e-01,  7.3337e-02,  1.5934e-01,\n",
      "          1.1772e-01, -7.3549e-02, -2.2394e-01, -2.5215e-01, -4.1644e-02],\n",
      "        [-1.1517e-01, -1.8579e-01, -2.3456e-02,  3.2845e-02,  4.2607e-02,\n",
      "         -5.0134e-02, -1.9715e-02,  1.1680e-01,  1.3121e-02,  5.9445e-03,\n",
      "          1.9801e-01,  1.2369e-01,  1.1552e-01,  1.1459e-01, -4.9943e-02,\n",
      "         -2.0446e-02, -3.8584e-02,  1.5196e-01,  1.8568e-01,  2.2142e-01,\n",
      "          1.0811e-01,  1.3749e-02,  1.3548e-01,  3.6956e-02,  1.0059e-02],\n",
      "        [ 6.6090e-02, -2.2241e-01, -9.5229e-02,  1.6574e-01, -2.1203e-01,\n",
      "          2.9635e-01, -4.1787e-01, -1.3404e-01, -1.5415e-01,  1.0804e-01,\n",
      "         -4.3579e-01,  2.3215e-01,  1.4817e-01, -1.7789e-01, -4.6622e-03,\n",
      "         -2.6494e-02, -3.9969e-01, -4.3328e-02, -1.1619e-01, -2.7971e-01,\n",
      "         -3.4989e-01, -1.7614e-02, -3.7330e-01,  1.2444e-01, -9.9457e-02],\n",
      "        [-2.0265e-01,  6.4782e-02,  3.3976e-01,  7.6993e-02,  1.0224e-01,\n",
      "         -1.4419e-01, -1.2314e-01, -1.0445e-01,  4.9229e-02,  5.3221e-02,\n",
      "          2.9089e-01,  3.4033e-02,  6.7439e-02, -5.9153e-02,  1.3080e-01,\n",
      "          1.4491e-01, -2.4055e-01,  1.4809e-01, -1.0437e-01,  1.9013e-01,\n",
      "         -1.6626e-02, -2.0027e-01,  4.7152e-01,  1.4186e-01, -1.2168e-01],\n",
      "        [-7.1863e-02, -1.1384e-01,  2.2278e-02,  1.4069e-01,  1.6530e-01,\n",
      "         -1.2882e-01,  8.6198e-02, -1.4645e-01, -5.8743e-02, -1.0057e-03,\n",
      "         -1.7163e-01,  1.2048e-01,  1.0552e-01,  1.2904e-01, -4.9031e-03,\n",
      "          9.4673e-02,  1.2338e-01,  7.4458e-02, -1.2355e-02, -9.2009e-02,\n",
      "          2.6882e-02,  2.8837e-01, -3.4767e-01, -3.4791e-02, -1.8993e-01],\n",
      "        [-1.9581e-01,  2.4458e-01, -1.0421e-01,  1.3276e-01,  2.1246e-01,\n",
      "         -8.9615e-02, -2.2078e-01,  3.0893e-01, -3.5277e-02,  1.7431e-01,\n",
      "         -4.4377e-01, -4.0874e-01,  7.9254e-02,  3.5037e-02, -2.6223e-01,\n",
      "         -4.9175e-02, -3.3795e-01, -1.3919e-02,  3.1069e-01,  1.0907e-01,\n",
      "         -3.5093e-01,  7.5226e-02, -3.6208e-01, -3.4323e-01,  2.5888e-01],\n",
      "        [ 4.0346e-02,  6.0806e-02, -2.7251e-01,  2.6509e-01,  8.4619e-02,\n",
      "          1.4567e-01, -2.3627e-01,  3.4358e-01,  1.1992e-01, -4.6565e-03,\n",
      "          1.6203e-01,  9.5051e-02, -2.6405e-01, -1.4497e-01, -2.1649e-01,\n",
      "         -1.9610e-01, -1.0713e-01, -2.0007e-01,  2.3142e-01,  1.8905e-01,\n",
      "         -1.8697e-01,  3.7257e-01,  9.9284e-03,  4.5917e-01,  9.4791e-02],\n",
      "        [ 9.7705e-02, -6.8090e-02, -3.6513e-01, -2.0414e-01, -1.2794e-01,\n",
      "          7.4120e-03, -3.4083e-02,  2.2583e-01, -1.6874e-01, -5.6840e-02,\n",
      "         -2.6181e-01,  1.5950e-01,  1.4109e-01, -9.3298e-02, -3.1462e-01,\n",
      "          9.6898e-02,  6.3449e-02, -4.0322e-02, -5.1093e-02, -6.9264e-02,\n",
      "          2.6139e-01,  4.4098e-01,  1.5524e-01,  1.1623e-01, -2.5053e-01]])\n",
      "None tensor([ 0.0205,  0.1438,  0.0334, -0.1235,  0.0927, -0.0265, -0.0842,  0.0637,\n",
      "         0.1101,  0.0876, -0.1053,  0.2357,  0.0521, -0.1240,  0.1105, -0.0706,\n",
      "         0.0551, -0.1010, -0.0869, -0.0889,  0.0146,  0.1115, -0.1358, -0.0400,\n",
      "        -0.0385])\n",
      "None tensor([[-1.1644e-01,  2.3118e-01, -2.6683e-02,  1.9151e-01,  3.3047e-01,\n",
      "         -1.7617e-01,  1.1384e-01, -1.2390e-01,  2.9315e-01, -7.4269e-02,\n",
      "          1.2341e-01, -1.3459e-02, -8.3012e-02,  4.1221e-01, -9.0055e-02,\n",
      "          3.8175e-01,  1.5570e-01,  5.4776e-02,  1.4202e-02, -2.6670e-01,\n",
      "          2.1515e-01,  1.4746e-01, -1.1516e-01,  2.9928e-01,  3.4076e-01],\n",
      "        [ 1.1414e-01,  1.5296e-01, -2.0282e-01, -6.2677e-02, -8.6506e-02,\n",
      "         -2.0280e-01,  3.3639e-02, -5.7563e-02, -1.6769e-01, -1.0584e-01,\n",
      "         -2.7239e-02, -8.1638e-02, -1.2083e-01, -1.2805e-01,  2.8963e-02,\n",
      "         -1.9228e-01, -1.4537e-01, -5.5617e-02,  1.3670e-01,  1.4139e-01,\n",
      "          1.4598e-01, -1.0345e-01,  1.4467e-01, -9.0082e-02, -1.1400e-01],\n",
      "        [-1.5504e-01,  9.7653e-02,  1.0983e-01,  1.8528e-01,  1.9222e-01,\n",
      "          9.5787e-02,  1.0809e-01, -3.2086e-01,  8.0398e-02, -1.9764e-01,\n",
      "          3.0263e-01, -1.0139e-02,  1.7673e-01,  5.6115e-01,  5.5583e-02,\n",
      "          1.8676e-01,  2.7985e-01, -3.3053e-02,  1.6033e-01, -1.7473e-01,\n",
      "         -3.3392e-02, -1.2367e-01, -3.3797e-01,  5.6399e-01,  2.4914e-01],\n",
      "        [ 1.5374e-01,  1.9034e-01,  1.4203e-01,  1.7243e-01,  2.7305e-01,\n",
      "         -1.1061e-02,  1.2346e-01, -1.2784e-01,  3.6097e-01, -1.5223e-02,\n",
      "          1.5413e-01,  2.4940e-01,  2.1278e-01,  2.5982e-01, -1.3231e-01,\n",
      "          2.9383e-01,  1.8364e-01, -1.9433e-01,  4.5636e-02, -3.0127e-01,\n",
      "          2.3079e-01, -2.2163e-01, -2.7440e-01,  3.9328e-01,  1.1454e-02],\n",
      "        [ 1.6255e-01,  1.6407e-01, -2.1875e-02,  2.0703e-01,  5.4958e-01,\n",
      "          2.9645e-02,  3.4810e-01, -2.0709e-01,  3.7966e-01, -2.5904e-01,\n",
      "          2.1046e-01,  2.7954e-01,  3.0567e-01,  4.6974e-01, -4.1023e-02,\n",
      "          2.6142e-01,  1.2297e-01, -2.8971e-02, -1.2289e-01, -2.1820e-01,\n",
      "          6.4895e-02,  2.4228e-03, -2.9577e-01,  7.5278e-01,  7.7601e-02],\n",
      "        [ 1.9460e-01, -6.9881e-02, -4.1566e-02,  7.0977e-03, -1.4289e-01,\n",
      "          1.5340e-01,  4.8328e-02,  2.2264e-01, -2.6776e-01,  1.7691e-01,\n",
      "         -2.6474e-01,  1.6355e-03, -4.2847e-02, -2.6494e-01,  2.5000e-01,\n",
      "         -8.0162e-02, -2.6960e-01,  1.3571e-02,  2.5024e-01,  1.3458e-01,\n",
      "         -2.9651e-01,  2.4190e-01,  4.1572e-01, -3.0072e-01, -3.5931e-01],\n",
      "        [-3.9748e-02,  3.4756e-01,  3.2141e-02,  2.8831e-01,  6.3692e-01,\n",
      "          4.5094e-02,  9.4264e-02, -2.8765e-01,  1.6950e-01, -2.0606e-01,\n",
      "          1.7582e-01,  7.1634e-02,  4.8776e-02,  4.5509e-01, -7.0687e-02,\n",
      "          3.0398e-01,  2.4597e-01,  1.9479e-01, -2.6061e-02, -2.7616e-01,\n",
      "          3.3703e-01,  1.3945e-01, -2.1998e-01,  6.0206e-01,  2.4523e-01],\n",
      "        [-1.4271e-01,  1.0576e-01, -1.2201e-01, -4.5656e-02, -3.5319e-02,\n",
      "         -2.2099e-01, -3.8412e-02,  3.5921e-01, -1.8815e-01,  1.1700e-01,\n",
      "          1.1912e-01, -1.9737e-02,  1.3385e-01,  2.7986e-02, -4.1215e-03,\n",
      "         -9.3374e-02, -3.6294e-01,  2.1581e-01, -9.5425e-02,  3.9873e-01,\n",
      "         -3.4686e-01,  8.6823e-02, -3.6645e-01, -1.8370e-01, -2.3781e-01],\n",
      "        [ 2.4421e-02,  3.3420e-02,  7.5626e-02, -1.2672e-01, -2.3000e-01,\n",
      "         -4.8866e-05, -3.1237e-01,  3.4267e-01, -2.0440e-01,  4.3278e-01,\n",
      "         -2.0445e-01,  2.7313e-01, -4.6634e-02, -3.5224e-01,  8.8752e-03,\n",
      "         -2.4140e-01, -3.4785e-01,  3.1365e-02,  1.4978e-01,  4.6281e-01,\n",
      "          1.6165e-03,  3.3577e-01,  5.5398e-01, -3.6618e-01,  1.5084e-03],\n",
      "        [ 9.3146e-02, -1.6733e-01, -1.8371e-02, -1.5719e-01, -1.3947e-01,\n",
      "         -5.4758e-02, -1.3104e-01, -1.9664e-01,  5.3596e-02, -1.4733e-01,\n",
      "          1.3097e-01,  9.1253e-02, -1.9137e-01,  1.2715e-01,  8.7464e-03,\n",
      "          5.3723e-02, -1.8768e-01,  1.2380e-01, -6.2231e-02, -3.7226e-02,\n",
      "         -1.2188e-01, -7.3274e-02,  1.8764e-01,  7.6155e-03, -2.8694e-02],\n",
      "        [ 2.0323e-01,  2.1536e-01, -1.9599e-02,  3.6458e-01,  4.1863e-01,\n",
      "          1.4824e-02,  1.9763e-01, -3.6095e-02,  1.1811e-01, -8.9459e-02,\n",
      "          8.6408e-02,  2.6159e-01,  1.9756e-01,  2.2691e-01,  3.7801e-03,\n",
      "          4.3226e-01, -9.6753e-03,  2.5400e-02,  1.4827e-01, -2.8340e-01,\n",
      "          1.2759e-01, -5.5052e-02, -1.9741e-01,  5.4628e-01,  4.1036e-02],\n",
      "        [-3.8331e-02,  9.3578e-02,  1.2720e-01,  3.8249e-01,  4.7178e-01,\n",
      "          1.2353e-01,  4.2232e-01, -1.2663e-01,  4.6826e-01, -2.3630e-01,\n",
      "          1.3268e-01,  3.3941e-01,  3.7008e-02,  5.9368e-01, -1.4137e-01,\n",
      "          2.2266e-01,  3.8313e-01,  1.8803e-01, -8.5513e-02, -3.5573e-01,\n",
      "          1.0114e-01, -1.3106e-01, -3.7873e-01,  5.7881e-01,  2.4371e-01],\n",
      "        [ 1.5293e-01,  1.0614e-01,  1.8080e-01,  2.9304e-01,  4.0035e-01,\n",
      "          1.3174e-02,  2.7282e-01, -1.9459e-01,  9.7997e-02, -3.0936e-02,\n",
      "          3.0335e-01, -1.0994e-02,  2.5171e-01,  5.0267e-01,  3.0251e-02,\n",
      "          2.6255e-01,  9.8783e-03,  3.1806e-02,  5.1914e-02, -2.4164e-01,\n",
      "          1.1837e-01, -8.0167e-02, -2.6480e-01,  3.3066e-01,  1.3221e-02],\n",
      "        [ 1.6220e-01,  5.4061e-02,  2.0796e-01,  1.3094e-01,  1.2145e-01,\n",
      "          3.4389e-02,  2.0110e-02, -8.7403e-02,  4.5671e-02, -1.0697e-01,\n",
      "          2.0278e-01,  1.0585e-01,  1.7849e-03,  4.0792e-01,  1.4605e-01,\n",
      "          2.4640e-01, -4.1981e-02,  3.4047e-02, -5.9737e-02, -8.5019e-02,\n",
      "          4.1082e-03,  3.3284e-02, -1.5412e-01,  4.2505e-01,  1.3229e-01],\n",
      "        [ 6.8020e-02,  2.9987e-01,  8.9527e-03,  2.0280e-01,  5.8724e-01,\n",
      "          7.0497e-02,  2.9623e-01, -1.3639e-01,  3.8305e-01, -1.4377e-01,\n",
      "          1.4849e-01,  9.9652e-02,  5.7254e-02,  8.4437e-01,  1.8813e-02,\n",
      "          3.7184e-01,  9.6659e-02, -3.2909e-02,  6.9213e-02, -2.3424e-01,\n",
      "          1.5214e-01, -3.7336e-02, -2.9411e-01,  5.3003e-01,  2.6767e-01],\n",
      "        [-2.7983e-01, -1.3072e-01, -4.7880e-03,  3.4005e-01,  6.8637e-01,\n",
      "          6.9083e-02,  2.1392e-02, -2.8432e-01,  3.6306e-01,  1.7145e-01,\n",
      "          2.4005e-01,  3.0196e-01, -2.3646e-01,  7.6590e-01, -4.6285e-02,\n",
      "          3.5723e-01,  2.1816e-01,  1.7348e-02,  1.6706e-01, -3.6333e-01,\n",
      "          4.4861e-01, -1.1312e-01, -3.6757e-01,  3.8495e-01, -1.8057e-01],\n",
      "        [ 1.4277e-01,  3.0554e-01,  2.0041e-01,  1.1491e-01,  4.5208e-01,\n",
      "          1.1725e-01,  3.2728e-01, -3.0090e-01,  7.3535e-02, -1.9922e-01,\n",
      "          3.0407e-01,  2.2859e-01,  5.4592e-02,  5.9979e-01, -8.6571e-02,\n",
      "          2.3984e-01,  3.7353e-01, -2.3185e-02,  6.2718e-02, -2.0856e-01,\n",
      "          2.9279e-01, -5.9968e-02, -3.0946e-01,  5.5303e-01,  4.4031e-02],\n",
      "        [ 1.2999e-02,  1.3626e-01,  1.2853e-01,  3.7870e-01,  5.7073e-01,\n",
      "          9.6141e-02,  2.4180e-01, -1.6143e-01,  4.1487e-01, -2.4199e-01,\n",
      "          3.8758e-01,  6.1175e-02,  3.1664e-01,  6.5235e-01, -1.4109e-01,\n",
      "          2.5851e-01,  4.6034e-01,  2.4915e-01, -1.3627e-01, -2.8339e-01,\n",
      "          3.5928e-01, -1.4963e-01, -2.7418e-01,  4.7478e-01,  1.9852e-01],\n",
      "        [ 4.9983e-02,  2.9133e-01,  2.1228e-01,  2.3534e-01,  4.6241e-01,\n",
      "          1.2304e-01,  2.1895e-01, -2.5231e-01,  2.7314e-01, -1.9745e-01,\n",
      "          1.5010e-01,  1.7359e-01,  1.4899e-01,  5.8545e-01, -2.2812e-01,\n",
      "          2.8177e-01,  3.5420e-01, -1.1188e-01, -2.0257e-01, -1.1215e-01,\n",
      "          3.2978e-01, -9.1035e-03, -2.5104e-01,  2.9659e-01,  1.2302e-01],\n",
      "        [ 9.3970e-02,  5.4304e-02,  2.1177e-03,  1.5669e-01,  2.9662e-01,\n",
      "         -4.3377e-02,  2.5675e-01, -3.2446e-01,  3.2751e-01, -3.2418e-01,\n",
      "          6.6097e-03,  3.4225e-01,  1.5629e-01,  5.5509e-01,  1.6247e-01,\n",
      "          4.3164e-01,  3.0832e-01, -1.4309e-01, -2.4300e-02,  2.0889e-03,\n",
      "          1.4808e-02,  1.5828e-01, -1.8404e-01,  6.2570e-01,  3.8121e-01],\n",
      "        [ 4.1787e-02,  4.7474e-02,  1.8319e-01, -1.3287e-01, -1.8870e-01,\n",
      "          1.7005e-01, -1.6227e-01,  4.2695e-01, -3.8282e-02,  3.7018e-01,\n",
      "         -6.2102e-02, -4.0492e-02, -1.5422e-01, -3.0759e-01,  1.8259e-01,\n",
      "         -2.2656e-01, -1.7488e-01, -3.0519e-02, -7.6541e-02,  1.4662e-01,\n",
      "          2.7374e-03,  9.8550e-02,  1.8161e-01, -4.7692e-01,  6.6082e-02],\n",
      "        [ 1.0587e-01, -7.1112e-02,  6.0830e-02,  1.2820e-02,  3.4902e-02,\n",
      "         -1.7323e-02,  2.0862e-02,  1.7299e-02,  2.8375e-02,  1.7453e-01,\n",
      "          3.8677e-03,  1.2140e-01,  1.4072e-01, -7.7265e-02,  1.6365e-02,\n",
      "         -5.7762e-02,  1.3729e-02, -6.4789e-02,  9.7968e-02,  7.6604e-02,\n",
      "          3.2553e-02, -2.4859e-03,  3.1146e-01,  2.9267e-02,  5.3057e-02],\n",
      "        [ 4.1239e-02, -9.8500e-02, -8.4061e-02,  3.7795e-03, -1.7709e-01,\n",
      "         -1.7067e-01,  4.1212e-02,  1.7137e-01,  1.2323e-01, -8.7340e-02,\n",
      "         -1.7535e-01, -7.9898e-02, -1.5103e-01,  1.4798e-01, -1.9658e-01,\n",
      "         -1.4072e-02, -4.1180e-02,  3.3036e-02,  9.8626e-02, -1.6813e-01,\n",
      "          6.9253e-03,  9.1314e-02, -1.5011e-01, -1.2827e-01, -9.4641e-02],\n",
      "        [-1.4581e-01,  2.2789e-01,  2.1041e-01,  2.4174e-01,  4.9394e-01,\n",
      "         -1.1384e-01,  7.5808e-02, -1.6789e-01,  4.0705e-01, -1.5242e-01,\n",
      "          8.3146e-02,  2.3477e-01, -1.9175e-02,  3.0511e-01, -7.2570e-02,\n",
      "          3.3274e-01,  3.2045e-01,  1.6419e-01,  1.0887e-01, -2.2994e-01,\n",
      "          1.4814e-01, -1.2838e-01, -3.0423e-01,  5.4149e-01,  3.6891e-01],\n",
      "        [ 1.6655e-01,  9.2041e-02,  6.3517e-02,  1.0023e-01,  3.9972e-01,\n",
      "          1.0826e-01,  3.0026e-01, -3.5621e-01,  1.8325e-01, -1.3643e-01,\n",
      "          5.9662e-02,  2.8810e-01,  9.8369e-02,  4.3946e-01, -1.3101e-01,\n",
      "          2.0961e-01,  8.6261e-02,  1.6236e-01,  1.5699e-01, -2.6137e-01,\n",
      "          3.2875e-01, -6.4947e-03, -3.5342e-01,  3.7968e-01,  3.3036e-01]])\n",
      "None tensor([ 0.1216, -0.1780,  0.1002,  0.1311,  0.0319,  0.2743, -0.0359,  0.1653,\n",
      "         0.1807, -0.1965, -0.0792,  0.0022,  0.0144,  0.0009, -0.1097, -0.0313,\n",
      "         0.0418, -0.0241,  0.1306, -0.0090,  0.0566, -0.2136, -0.2164,  0.1371,\n",
      "         0.0198])\n",
      "None tensor([[ 0.2086, -0.1586,  0.1712,  0.1990,  0.4951, -0.2947,  0.2472, -0.3472,\n",
      "         -0.4721, -0.1467,  0.2225,  0.6174,  0.2781,  0.1421,  0.6482,  0.4275,\n",
      "          0.3503,  0.4680, -0.0119,  0.1213, -0.2875, -0.2169,  0.1018,  0.2160,\n",
      "          0.2418],\n",
      "        [-0.0899, -0.1531, -0.2437, -0.1290, -0.5589,  0.1079, -0.2368,  0.2779,\n",
      "          0.2755, -0.0078, -0.2266, -0.7431, -0.1100,  0.0886, -0.4668, -0.4879,\n",
      "         -0.3101, -0.6880, -0.2812, -0.2897,  0.1700,  0.1490,  0.1088, -0.1225,\n",
      "         -0.2908]])\n",
      "None tensor([-0.0996,  0.0883])\n"
     ]
    }
   ],
   "source": [
    "for p in ps_model.network.parameters():\n",
    "    if p.requires_grad:\n",
    "         print(p.name, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated_generated, ps_score_list_treated = gan.eval_GAN(tuple_unmatched_control[0].shape[0],\n",
    "                                                                device)\n",
    "len(ps_score_list_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# treated by GAN vs unmactched control\n",
    "draw(ps_score_list_treated, ps_un_matched_control_list, bins1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TARNetPhi(nn.Module):\n",
    "    def __init__(self, input_nodes, shared_nodes=200):\n",
    "        super(TARNetPhi, self).__init__()\n",
    "\n",
    "        # shared layer\n",
    "        self.shared1 = nn.Linear(in_features=input_nodes, out_features=shared_nodes)\n",
    "        nn.init.xavier_uniform_(self.shared1.weight)\n",
    "        nn.init.zeros_(self.shared1.bias)\n",
    "\n",
    "        self.shared2 = nn.Linear(in_features=shared_nodes, out_features=shared_nodes)\n",
    "        nn.init.xavier_uniform_(self.shared2.weight)\n",
    "        nn.init.zeros_(self.shared2.bias)\n",
    "\n",
    "        self.shared3 = nn.Linear(in_features=shared_nodes, out_features=shared_nodes)\n",
    "        nn.init.xavier_uniform_(self.shared3.weight)\n",
    "        nn.init.zeros_(self.shared3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "        # shared layers\n",
    "        x = F.relu(self.shared1(x))\n",
    "        x = F.relu(self.shared2(x))\n",
    "        x = F.relu(self.shared3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TARNetH_Y1(nn.Module):\n",
    "    def __init__(self, input_nodes=200, outcome_nodes=100):\n",
    "        super(TARNetH_Y1, self).__init__()\n",
    "\n",
    "        # potential outcome1 Y(1)\n",
    "        self.hidden1_Y1 = nn.Linear(in_features=input_nodes, out_features=outcome_nodes)\n",
    "        nn.init.xavier_uniform_(self.hidden1_Y1.weight)\n",
    "        nn.init.zeros_(self.hidden1_Y1.bias)\n",
    "\n",
    "        self.hidden2_Y1 = nn.Linear(in_features=outcome_nodes, out_features=outcome_nodes)\n",
    "        nn.init.xavier_uniform_(self.hidden2_Y1.weight)\n",
    "        nn.init.zeros_(self.hidden2_Y1.bias)\n",
    "\n",
    "        self.out_Y1 = nn.Linear(in_features=outcome_nodes, out_features=1)\n",
    "        nn.init.xavier_uniform_(self.out_Y1.weight)\n",
    "        nn.init.zeros_(self.out_Y1.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        # potential outcome1 Y(1)\n",
    "        y1 = F.relu(self.hidden1_Y1(x))\n",
    "        y1 = F.relu(self.hidden2_Y1(y1))\n",
    "        y1 = self.out_Y1(y1)\n",
    "\n",
    "        return y1\n",
    "\n",
    "\n",
    "class TARNetH_Y0(nn.Module):\n",
    "    def __init__(self, input_nodes=200, outcome_nodes=100):\n",
    "        super(TARNetH_Y0, self).__init__()\n",
    "\n",
    "        # potential outcome1 Y(0)\n",
    "        self.hidden1_Y0 = nn.Linear(in_features=input_nodes, out_features=outcome_nodes)\n",
    "        nn.init.xavier_uniform_(self.hidden1_Y0.weight)\n",
    "        nn.init.zeros_(self.hidden1_Y0.bias)\n",
    "\n",
    "        self.hidden2_Y0 = nn.Linear(in_features=outcome_nodes, out_features=outcome_nodes)\n",
    "        nn.init.xavier_uniform_(self.hidden2_Y0.weight)\n",
    "        nn.init.zeros_(self.hidden2_Y0.bias)\n",
    "\n",
    "        self.out_Y0 = nn.Linear(in_features=outcome_nodes, out_features=1)\n",
    "        nn.init.xavier_uniform_(self.out_Y0.weight)\n",
    "        nn.init.zeros_(self.out_Y0.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        # potential outcome1 Y(0)\n",
    "        y0 = F.relu(self.hidden1_Y0(x))\n",
    "        y0 = F.relu(self.hidden2_Y0(y0))\n",
    "        y0 = self.out_Y0(y0)\n",
    "\n",
    "        return y0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PS_Matching:\n",
    "    def match_using_prop_score(self, tuple_treated, tuple_control):\n",
    "        matched_controls = []\n",
    "\n",
    "        # do ps match\n",
    "        np_treated_df_X, np_treated_ps_score, np_treated_df_Y_f, np_treated_df_Y_cf = tuple_treated\n",
    "        np_control_df_X, np_control_ps_score, np_control_df_Y_f, np_control_df_Y_cf = tuple_control\n",
    "\n",
    "        # get unmatched controls\n",
    "        matched_control_indices, unmatched_control_indices = self.get_matched_and_unmatched_control_indices(\n",
    "            Utils.convert_to_col_vector(np_treated_ps_score),\n",
    "            Utils.convert_to_col_vector(np_control_ps_score))\n",
    "\n",
    "        tuple_matched_control, tuple_unmatched_control = self.filter_matched_and_unmatched_control_samples(\n",
    "            np_control_df_X, np_control_ps_score,\n",
    "            np_control_df_Y_f,\n",
    "            np_control_df_Y_cf, matched_control_indices,\n",
    "            unmatched_control_indices)\n",
    "\n",
    "        return tuple_matched_control\n",
    "\n",
    "    def filter_matched_and_unmatched_control_samples(self, np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f,\n",
    "                                                     np_control_df_Y_cf, matched_control_indices,\n",
    "                                                     unmatched_control_indices):\n",
    "        tuple_matched_control = self.filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                                                           np_control_df_Y_f,\n",
    "                                                           np_control_df_Y_cf,\n",
    "                                                           matched_control_indices)\n",
    "\n",
    "        tuple_unmatched_control = self.filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                                                             np_control_df_Y_f,\n",
    "                                                             np_control_df_Y_cf,\n",
    "                                                             unmatched_control_indices)\n",
    "\n",
    "        return tuple_matched_control, tuple_unmatched_control\n",
    "\n",
    "    @staticmethod\n",
    "    def filter_control_groups(np_control_df_X, np_control_ps_score,\n",
    "                              np_control_df_Y_f,\n",
    "                              np_control_df_Y_cf, indices):\n",
    "        np_filter_control_df_X = np.take(np_control_df_X, indices, axis=0)\n",
    "        np_filter_control_ps_score = np.take(np_control_ps_score, indices, axis=0)\n",
    "        np_filter_control_df_Y_f = np.take(np_control_df_Y_f, indices, axis=0)\n",
    "        np_filter_control_df_Y_cf = np.take(np_control_df_Y_cf, indices, axis=0)\n",
    "        tuple_matched_control = (np_filter_control_df_X, np_filter_control_ps_score,\n",
    "                                 np_filter_control_df_Y_f, np_filter_control_df_Y_cf)\n",
    "\n",
    "        return tuple_matched_control\n",
    "\n",
    "    @staticmethod\n",
    "    def get_matched_and_unmatched_control_indices(ps_treated, ps_control):\n",
    "        nn = NearestNeighbors(n_neighbors=1)\n",
    "        nn.fit(ps_control)\n",
    "        distance, matched_control = nn.kneighbors(ps_treated)\n",
    "        matched_control_indices = np.array(matched_control).ravel()\n",
    "\n",
    "        # remove duplicates\n",
    "        # matched_control_indices = list(dict.fromkeys(matched_control_indices))\n",
    "        set_matched_control_indices = set(matched_control_indices)\n",
    "        total_indices = list(range(len(ps_control)))\n",
    "        unmatched_control_indices = list(filter(lambda x: x not in set_matched_control_indices,\n",
    "                                                total_indices))\n",
    "\n",
    "        return matched_control_indices, unmatched_control_indices\n",
    "\n",
    "    @staticmethod\n",
    "    def get_unmatched_prop_list(tensor_unmatched_control):\n",
    "        control_data_loader_train = torch.utils.data.DataLoader(tensor_unmatched_control,\n",
    "                                                                batch_size=1,\n",
    "                                                                shuffle=False,\n",
    "                                                                num_workers=1)\n",
    "        ps_unmatched_control_list = []\n",
    "        for batch in control_data_loader_train:\n",
    "            covariates_X, ps_score, y_f, y_cf = batch\n",
    "            ps_unmatched_control_list.append(ps_score.item())\n",
    "\n",
    "        return ps_unmatched_control_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceNet:\n",
    "    def __init__(self, input_nodes, shared_nodes, outcome_nodes, device):\n",
    "        self.tarnet_phi = TARNetPhi(input_nodes, shared_nodes=shared_nodes).to(device)\n",
    "\n",
    "        self.tarnet_h_y1 = TARNetH_Y1(input_nodes=shared_nodes,\n",
    "                                      outcome_nodes=outcome_nodes).to(device)\n",
    "\n",
    "        self.tarnet_h_y0 = TARNetH_Y0(input_nodes=shared_nodes,\n",
    "                                      outcome_nodes=outcome_nodes).to(device)\n",
    "\n",
    "    def get_tarnet_phi(self):\n",
    "        return self.tarnet_phi\n",
    "\n",
    "    def get_tarnet_h_y1(self):\n",
    "        return self.tarnet_h_y1\n",
    "\n",
    "    def get_tarnet_h_y0_model(self):\n",
    "        return self.tarnet_h_y0\n",
    "\n",
    "    def train_semi_supervised(self, train_parameters, n_total, n_treated, device):\n",
    "        epochs = train_parameters[\"epochs\"]\n",
    "        batch_size = train_parameters[\"batch_size\"]\n",
    "        lr = train_parameters[\"lr\"]\n",
    "        weight_decay = train_parameters[\"lambda\"]\n",
    "        shuffle = train_parameters[\"shuffle\"]\n",
    "        tensor_dataset = train_parameters[\"tensor_dataset\"]\n",
    "        u = n_treated / n_total\n",
    "        weight_t = 1 / (2 * u)\n",
    "        weight_c = 1 / (2 * (1 - u))\n",
    "\n",
    "        treated_data_loader_train = torch.utils.data.DataLoader(tensor_dataset,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                shuffle=shuffle,\n",
    "                                                                num_workers=1)\n",
    "\n",
    "        optimizer_W = optim.Adam(self.tarnet_phi.parameters(), lr=lr)\n",
    "        optimizer_V1 = optim.Adam(self.tarnet_h_y1.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        optimizer_V2 = optim.Adam(self.tarnet_h_y0.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        lossF = nn.MSELoss()\n",
    "        print(\".. Training started ..\")\n",
    "        print(device)\n",
    "        for epoch in range(epochs):\n",
    "            epoch += 1\n",
    "            total_loss_T = 0\n",
    "            total_loss_C = 0\n",
    "            for batch in treated_data_loader_train:\n",
    "                covariates_X, ps_score, T, y_f, y_cf = batch\n",
    "                covariates_X = covariates_X.to(device)\n",
    "                ps_score = ps_score.squeeze().to(device)\n",
    "\n",
    "                idx = (T == 1)\n",
    "                covariates_X_treated = covariates_X[idx]\n",
    "                y_f_treated = y_f[idx]\n",
    "                covariates_X_control = covariates_X[~idx]\n",
    "                y_f_control = y_f[~idx]\n",
    "\n",
    "                treated_size = covariates_X_treated.size(0)\n",
    "                control_size = covariates_X_control.size(0)\n",
    "                \n",
    "                optimizer_W.zero_grad()\n",
    "                optimizer_V1.zero_grad()\n",
    "                optimizer_V2.zero_grad()\n",
    "\n",
    "                if treated_size > 0:\n",
    "                    y1_hat = self.tarnet_h_y1(self.tarnet_phi(covariates_X_treated))\n",
    "                    if torch.cuda.is_available():\n",
    "                        loss_T = weight_t * lossF(y1_hat.float().cuda(),\n",
    "                                                  y_f_treated.float().cuda()).to(device)\n",
    "                    else:\n",
    "                        loss_T = weight_t * lossF(y1_hat.float(),\n",
    "                                                  y_f_treated.float()).to(device)\n",
    "                    loss_T.backward()\n",
    "                    total_loss_T += loss_T.item()\n",
    "\n",
    "                if control_size > 0:\n",
    "                    y0_hat = self.tarnet_h_y0(self.tarnet_phi(covariates_X_control))\n",
    "                    if torch.cuda.is_available():\n",
    "                        loss_C = weight_c * lossF(y0_hat.float().cuda(),\n",
    "                                                  y_f_control.float().cuda()).to(device)\n",
    "                    else:\n",
    "                        loss_C = weight_c * lossF(y0_hat.float(),\n",
    "                                                  y_f_control.float()).to(device)\n",
    "                    loss_C.backward()\n",
    "                    total_loss_C += loss_C.item()\n",
    "\n",
    "\n",
    "\n",
    "                optimizer_W.step()\n",
    "\n",
    "                if treated_size > 0:\n",
    "                    optimizer_V1.step()\n",
    "                if control_size > 0:\n",
    "                    optimizer_V2.step()\n",
    "\n",
    "            if epoch % 40 == 0:\n",
    "                print(\"epoch: {0}, Treated + Control loss: {1}\".format(epoch, total_loss_T + total_loss_C))\n",
    "\n",
    "    def eval_semi_supervised(self, eval_parameters, device, treated_flag):\n",
    "        eval_set = eval_parameters[\"tensor_dataset\"]\n",
    "\n",
    "        _data_loader = torch.utils.data.DataLoader(eval_set,\n",
    "                                                   shuffle=False, num_workers=1)\n",
    "\n",
    "        y_f_list = []\n",
    "        y_cf_list = []\n",
    "\n",
    "        for batch in _data_loader:\n",
    "            covariates_X, ps_score = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "            ps_score = ps_score.squeeze().to(device)\n",
    "            y1_hat = self.tarnet_h_y1(self.tarnet_phi(covariates_X))\n",
    "            y0_hat = self.tarnet_h_y0(self.tarnet_phi(covariates_X))\n",
    "            if treated_flag:\n",
    "                y_f_list.append(y1_hat.item())\n",
    "                y_cf_list.append(y0_hat.item())\n",
    "            else:\n",
    "                y_f_list.append(y0_hat.item())\n",
    "                y_cf_list.append(y1_hat.item())\n",
    "\n",
    "        return {\n",
    "            \"y_f_list\": np.array(y_f_list),\n",
    "            \"y_cf_list\": np.array(y_cf_list)\n",
    "        }\n",
    "\n",
    "    def train(self, train_parameters, device):\n",
    "        epochs = train_parameters[\"epochs\"]\n",
    "        batch_size = train_parameters[\"batch_size\"]\n",
    "        lr = train_parameters[\"lr\"]\n",
    "        weight_decay = train_parameters[\"lambda\"]\n",
    "        shuffle = train_parameters[\"shuffle\"]\n",
    "        treated_tensor_dataset = train_parameters[\"treated_tensor_dataset\"]\n",
    "        tuple_control = train_parameters[\"tuple_control_train\"]\n",
    "\n",
    "        treated_data_loader_train = torch.utils.data.DataLoader(treated_tensor_dataset,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                shuffle=shuffle,\n",
    "                                                                num_workers=1)\n",
    "\n",
    "        optimizer_W = optim.Adam(self.tarnet_phi.parameters(), lr=lr)\n",
    "        optimizer_V1 = optim.Adam(self.tarnet_h_y1.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        optimizer_V2 = optim.Adam(self.tarnet_h_y0.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        lossF = nn.MSELoss()\n",
    "        print(\".. Training started ..\")\n",
    "        print(device)\n",
    "        for epoch in range(epochs):\n",
    "            epoch += 1\n",
    "            total_loss_T = 0\n",
    "            total_loss_C = 0\n",
    "            for batch in treated_data_loader_train:\n",
    "                covariates_X_treated, ps_score_treated, y_f_treated, y_cf_treated = batch\n",
    "                covariates_X_treated = covariates_X_treated.to(device)\n",
    "                ps_score_treated = ps_score_treated.squeeze().to(device)\n",
    "\n",
    "                _tuple_treated = self.get_np_tuple_from_tensor(covariates_X_treated, ps_score_treated,\n",
    "                                                               y_f_treated, y_cf_treated)\n",
    "                psm = PS_Matching()\n",
    "                tuple_matched_control = psm.match_using_prop_score(_tuple_treated, tuple_control)\n",
    "\n",
    "                covariates_X_control, ps_score_control, y_f_control, y_cf_control = \\\n",
    "                    self.get_tensor_from_np_tuple(tuple_matched_control)\n",
    "\n",
    "                y1_hat = self.tarnet_h_y1(self.tarnet_phi(covariates_X_treated))\n",
    "                y0_hat = self.tarnet_h_y0(self.tarnet_phi(covariates_X_control))\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    loss_T = lossF(y1_hat.float().cuda(),\n",
    "                                   y_f_treated.float().cuda()).to(device)\n",
    "                    loss_C = lossF(y0_hat.float().cuda(),\n",
    "                                   y_f_control.float().cuda()).to(device)\n",
    "                else:\n",
    "                    loss_T = lossF(y1_hat.float(),\n",
    "                                   y_f_treated.float()).to(device)\n",
    "                    loss_C = lossF(y0_hat.float(),\n",
    "                                   y_f_control.float()).to(device)\n",
    "\n",
    "                optimizer_W.zero_grad()\n",
    "                optimizer_V1.zero_grad()\n",
    "                optimizer_V2.zero_grad()\n",
    "                loss_T.backward()\n",
    "                loss_C.backward()\n",
    "                optimizer_W.step()\n",
    "                optimizer_V1.step()\n",
    "                optimizer_V2.step()\n",
    "                total_loss_T += loss_T.item()\n",
    "                total_loss_C += loss_C.item()\n",
    "\n",
    "            if epoch % 40 == 0:\n",
    "                print(\"epoch: {0}, Treated + Control loss: {1}\".format(epoch, total_loss_T + total_loss_C))\n",
    "\n",
    "    def eval(self, eval_parameters, device):\n",
    "        treated_set = eval_parameters[\"treated_set\"]\n",
    "        control_set = eval_parameters[\"control_set\"]\n",
    "        treated_data_loader = torch.utils.data.DataLoader(treated_set,\n",
    "                                                          shuffle=False, num_workers=1)\n",
    "        control_data_loader = torch.utils.data.DataLoader(control_set,\n",
    "                                                          shuffle=False, num_workers=1)\n",
    "\n",
    "        err_treated_list = []\n",
    "        err_control_list = []\n",
    "        true_ITE_list = []\n",
    "        predicted_ITE_list = []\n",
    "\n",
    "        ITE_dict_list = []\n",
    "\n",
    "        for batch in treated_data_loader:\n",
    "            covariates_X, ps_score, y_f, y_cf = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "            y1_hat = self.tarnet_h_y1(self.tarnet_phi(covariates_X))\n",
    "            y0_hat = self.tarnet_h_y0(self.tarnet_phi(covariates_X))\n",
    "\n",
    "            predicted_ITE = y1_hat - y0_hat\n",
    "            true_ITE = y_f - y_cf\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                diff = true_ITE.float().cuda() - predicted_ITE.float().cuda()\n",
    "            else:\n",
    "                diff = true_ITE.float() - predicted_ITE.float()\n",
    "\n",
    "            # ITE_dict_list.append(self.create_ITE_Dict(covariates_X,\n",
    "            #                                           ps_score.item(), y_f.item(),\n",
    "            #                                           y_cf.item(),\n",
    "            #                                           true_ITE.item(),\n",
    "            #                                           predicted_ITE.item(),\n",
    "            #                                           diff.item()))\n",
    "            err_treated_list.append(diff.item())\n",
    "            true_ITE_list.append(true_ITE.item())\n",
    "            predicted_ITE_list.append(predicted_ITE.item())\n",
    "\n",
    "        for batch in control_data_loader:\n",
    "            covariates_X, ps_score, y_f, y_cf = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "\n",
    "            y1_hat = self.tarnet_h_y1(self.tarnet_phi(covariates_X))\n",
    "            y0_hat = self.tarnet_h_y0(self.tarnet_phi(covariates_X))\n",
    "\n",
    "            predicted_ITE = y1_hat - y0_hat\n",
    "            true_ITE = y_cf - y_f\n",
    "            if torch.cuda.is_available():\n",
    "                diff = true_ITE.float().cuda() - predicted_ITE.float().cuda()\n",
    "            else:\n",
    "                diff = true_ITE.float() - predicted_ITE.float()\n",
    "\n",
    "            # ITE_dict_list.append(self.create_ITE_Dict(covariates_X,\n",
    "            #                                           ps_score.item(), y_f.item(),\n",
    "            #                                           y_cf.item(),\n",
    "            #                                           true_ITE.item(),\n",
    "            #                                           predicted_ITE.item(),\n",
    "            #                                           diff.item()))\n",
    "            err_control_list.append(diff.item())\n",
    "            true_ITE_list.append(true_ITE.item())\n",
    "            predicted_ITE_list.append(predicted_ITE.item())\n",
    "\n",
    "        # print(err_treated_list)\n",
    "        # print(err_control_list)\n",
    "        return {\n",
    "            \"treated_err\": err_treated_list,\n",
    "            \"control_err\": err_control_list,\n",
    "            \"true_ITE\": true_ITE_list,\n",
    "            \"predicted_ITE\": predicted_ITE_list,\n",
    "            \"ITE_dict_list\": ITE_dict_list\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_np_tuple_from_tensor(covariates_X, ps_score, y_f, y_cf):\n",
    "        np_covariates_X = covariates_X.numpy()\n",
    "        ps_score = ps_score.numpy()\n",
    "        y_f = y_f.numpy()\n",
    "        y_cf = y_cf.numpy()\n",
    "        _tuple = (np_covariates_X, ps_score, y_f, y_cf)\n",
    "\n",
    "        return _tuple\n",
    "\n",
    "    @staticmethod\n",
    "    def get_tensor_from_np_tuple(_tuple):\n",
    "        np_df_X, np_ps_score, np_df_Y_f, np_df_Y_cf = _tuple\n",
    "        return torch.from_numpy(np_df_X), torch.from_numpy(np_ps_score), \\\n",
    "               torch.from_numpy(np_df_Y_f), torch.from_numpy(np_df_Y_cf),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor_DCN_PS(tensor_x, ps_score):\n",
    "    tensor_ps_score = torch.from_numpy(ps_score)\n",
    "    processed_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_ps_score)\n",
    "    return processed_dataset\n",
    "\n",
    "def convert_to_tensor_DCN_semi_supervised(X, ps_score, T, Y_f, Y_cf):\n",
    "    tensor_x = torch.stack([torch.Tensor(i) for i in X])\n",
    "    tensor_ps_score = torch.from_numpy(ps_score)\n",
    "    tensor_T = torch.from_numpy(T)\n",
    "    tensor_y_f = torch.from_numpy(Y_f)\n",
    "    tensor_y_cf = torch.from_numpy(Y_cf)\n",
    "    processed_dataset = torch.utils.data.TensorDataset(tensor_x, tensor_ps_score, tensor_T,\n",
    "                                                           tensor_y_f, tensor_y_cf)\n",
    "    return processed_dataset    \n",
    "\n",
    "def create_tensors_to_train_DCN_semi_supervised(group):\n",
    "    np_df_X = group[0]\n",
    "    np_ps_score = group[1]\n",
    "    T = group[2]\n",
    "    np_df_Y_f = group[3]\n",
    "    np_df_Y_cf = group[4]\n",
    "    tensor = convert_to_tensor_DCN_semi_supervised(np_df_X, np_ps_score, T,\n",
    "                                             np_df_Y_f, np_df_Y_cf)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### DCN semi supervised training Unbalanced ###\n",
      "110\n",
      "487\n",
      "(597, 25)\n",
      ".. Training started ..\n",
      "cpu\n",
      "epoch: 40, Treated + Control loss: 2.851377987768501\n",
      "epoch: 80, Treated + Control loss: 1.1364887738600373\n",
      "epoch: 120, Treated + Control loss: 0.27669126307591796\n",
      "epoch: 160, Treated + Control loss: 4.617860727012157\n",
      "epoch: 200, Treated + Control loss: 0.023053019249346107\n"
     ]
    }
   ],
   "source": [
    "print(\"### DCN semi supervised training Unbalanced ###\")\n",
    "np_treated_x, np_treated_ps, np_treated_f, np_treated_cf = data_loader_dict_train[\"treated_data\"]\n",
    "np_control_x, np_control_ps, np_control_f, np_control_cf = data_loader_dict_train[\"control_data\"]\n",
    "\n",
    "t_1 = np.ones(np_treated_x.shape[0])\n",
    "t_0 = np.zeros(np_control_x.shape[0])\n",
    "\n",
    "n_treated = np_treated_x.shape[0]\n",
    "n_control = np_control_x.shape[0]\n",
    "n_total = n_treated + n_control\n",
    "\n",
    "np_train_ss_X = np.concatenate((np_treated_x, np_control_x), axis=0)\n",
    "np_train_ss_ps = np.concatenate((np_treated_ps, np_control_ps), axis=0)\n",
    "np_train_ss_T = np.concatenate((t_1, t_0), axis=0)\n",
    "np_train_ss_f = np.concatenate((np_treated_f, np_control_f), axis=0)\n",
    "np_train_ss_cf = np.concatenate((np_treated_cf, np_control_cf), axis=0)\n",
    "\n",
    "\n",
    "print(np_treated_x.shape[0])\n",
    "print(np_control_x.shape[0])\n",
    "print(np_train_ss_X.shape)\n",
    "\n",
    "train_set = create_tensors_to_train_DCN_semi_supervised((np_train_ss_X, np_train_ss_ps, \n",
    "                                                         np_train_ss_T, np_train_ss_f, \n",
    "                                                         np_train_ss_cf))\n",
    "train_parameters = {\n",
    "                \"epochs\": 200,\n",
    "                \"lr\": 1e-3,\n",
    "                \"lambda\":1e-4,\n",
    "                \"batch_size\": 64,\n",
    "                \"shuffle\": True,\n",
    "                \"tensor_dataset\": train_set\n",
    "    }\n",
    "\n",
    "inference_semi_supervised = InferenceNet(input_nodes=25, shared_nodes=200, \n",
    "                         outcome_nodes=100,\n",
    "                         device=device)\n",
    "\n",
    "inference_semi_supervised.train_semi_supervised(train_parameters, n_total, n_treated, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_list_treated_np = np.array(ps_score_list_treated)\n",
    "eval_set = convert_to_tensor_DCN_PS(treated_generated.detach(), ps_score_list_treated_np)\n",
    "\n",
    "DCN_test_parameters = {\n",
    "            \"tensor_dataset\": eval_set\n",
    "}\n",
    "treated_gen_y = inference_semi_supervised.eval_semi_supervised(DCN_test_parameters, device,\n",
    "                                                               treated_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi supervised balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sizes\n",
      "(110, 25)\n",
      "(110, 25)\n",
      ".. Training started ..\n",
      "cpu\n",
      "epoch: 40, Treated + Control loss: 1.4087359309196472\n",
      "epoch: 80, Treated + Control loss: 0.14168474357575178\n",
      "epoch: 120, Treated + Control loss: 0.004000059845566284\n",
      "epoch: 160, Treated + Control loss: 0.0018596424051793292\n",
      "epoch: 200, Treated + Control loss: 0.00023470999713026686\n",
      "epoch: 240, Treated + Control loss: 8.880044015313615e-05\n",
      "epoch: 280, Treated + Control loss: 0.00404468119086232\n",
      "epoch: 320, Treated + Control loss: 0.008151002461090684\n",
      "epoch: 360, Treated + Control loss: 0.1150625494774431\n",
      "epoch: 400, Treated + Control loss: 0.011322369158733636\n"
     ]
    }
   ],
   "source": [
    "_np_control_matched_X = tuple_matched_control[0]\n",
    "_np_ps_score_list_control_matched = tuple_matched_control[1]\n",
    "_np_control_matched_f = tuple_matched_control[2]\n",
    "_np_control_matched_cf = tuple_matched_control[3]\n",
    "\n",
    "_tuple_control_train = (_np_control_matched_X, _np_ps_score_list_control_matched, _np_control_matched_f, \n",
    "                           _np_control_matched_cf)\n",
    "\n",
    "_np_original_X = tuple_treated[0]\n",
    "_np_original_ps_score = tuple_treated[1]\n",
    "_np_original_Y_f = tuple_treated[2]\n",
    "_np_original_Y_cf = tuple_treated[3]\n",
    "\n",
    "print(\"Actual Sizes\")\n",
    "print(_np_control_matched_X.shape)\n",
    "print(_np_original_X.shape)\n",
    "\n",
    "_tensor_treated = Utils.convert_to_tensor_DCN(_np_original_X, _np_original_ps_score,\n",
    "                                            _np_original_Y_cf, _np_original_Y_f)\n",
    "\n",
    "train_parameters = {\n",
    "                \"epochs\": 400,\n",
    "                \"lr\": 1e-3,\n",
    "                \"lambda\":1e-4,\n",
    "                \"batch_size\": 100,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_tensor_dataset\": _tensor_treated,\n",
    "                \"tuple_control_train\": _tuple_control_train\n",
    "    }\n",
    "\n",
    "inference_ss_balanced = InferenceNet(input_nodes=25, shared_nodes=200, \n",
    "                         outcome_nodes=100,\n",
    "                         device=device)\n",
    "\n",
    "inference_ss_balanced.train(train_parameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_list_treated_np = np.array(ps_score_list_treated)\n",
    "eval_set = convert_to_tensor_DCN_PS(treated_generated.detach(), ps_score_list_treated_np)\n",
    "\n",
    "_test_parameters = {\n",
    "            \"tensor_dataset\": eval_set\n",
    "}\n",
    "treated_gen_y = inference_semi_supervised.eval_semi_supervised(_test_parameters, device,\n",
    "                                                               treated_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 1)\n",
      "(110, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 25)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_treated_generated = treated_generated.detach().numpy()\n",
    "np_ps_score_list_gen_treated = ps_score_list_treated_np\n",
    "\n",
    "# fliped = True\n",
    "np_treated_gen_f = Utils.convert_to_col_vector(treated_gen_y[\"y_f_list\"])\n",
    "np_treated_gen_cf = Utils.convert_to_col_vector(treated_gen_y[\"y_cf_list\"])\n",
    "\n",
    "print(np_treated_gen_f.shape)\n",
    "\n",
    "np_original_X = tuple_treated[0]\n",
    "np_original_ps_score = tuple_treated[1]\n",
    "np_original_Y_f = tuple_treated[2]\n",
    "np_original_Y_cf = tuple_treated[3]\n",
    "\n",
    "print(np_original_Y_f.shape)\n",
    "\n",
    "np_treated_x = np.concatenate((np_treated_generated, np_original_X), axis=0)\n",
    "np_treated_ps = np.concatenate((np_ps_score_list_gen_treated, np_original_ps_score), axis=0)\n",
    "np_treated_f = np.concatenate((np_treated_gen_f, np_original_Y_f), axis=0)\n",
    "np_treated_cf = np.concatenate((np_treated_gen_cf, np_original_Y_cf), axis=0)\n",
    "\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_x, np_treated_ps,\n",
    "                                            np_treated_f, np_treated_cf)\n",
    "\n",
    "np_treated_x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 1)\n",
      "(110, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(550, 25)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_control_unmatched_X = tuple_unmatched_control[0]\n",
    "np_ps_score_list_control_unmatched = tuple_unmatched_control[1]\n",
    "np_control_unmatched_f = tuple_unmatched_control[2]\n",
    "np_control_unmatched_cf = tuple_unmatched_control[3]\n",
    "\n",
    "np_control_matched_X = tuple_matched_control[0]\n",
    "np_ps_score_list_control_matched = tuple_matched_control[1]\n",
    "np_control_matched_f = tuple_matched_control[2]\n",
    "np_control_matched_cf = tuple_matched_control[3]\n",
    "\n",
    "print(np_control_unmatched_cf.shape)\n",
    "print(np_control_matched_cf.shape)\n",
    "\n",
    "np_control_x = np.concatenate((np_control_unmatched_X, np_control_matched_X), axis=0)\n",
    "np_control_ps = np.concatenate((np_ps_score_list_control_unmatched, np_ps_score_list_control_matched), axis=0)\n",
    "np_control_f = np.concatenate((np_control_unmatched_f, np_control_matched_f), axis=0)\n",
    "np_control_cf = np.concatenate((np_control_unmatched_cf, np_control_matched_cf), axis=0)\n",
    "\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_x, np_control_ps,\n",
    "                                            np_control_f, np_control_cf)\n",
    "\n",
    "\n",
    "np_control_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Sizes\n",
      "(550, 25)\n",
      "(550, 25)\n",
      ".. Training started ..\n",
      "cpu\n",
      "epoch: 40, Treated + Control loss: 0.8855374287813902\n",
      "epoch: 80, Treated + Control loss: 0.04655343806371093\n",
      "epoch: 120, Treated + Control loss: 0.07355194806586951\n",
      "epoch: 160, Treated + Control loss: 0.061962659179698676\n",
      "epoch: 200, Treated + Control loss: 0.006248871606658213\n",
      "epoch: 240, Treated + Control loss: 0.0025335157697554678\n",
      "epoch: 280, Treated + Control loss: 0.10758978070225567\n",
      "epoch: 320, Treated + Control loss: 0.011025349056581035\n",
      "epoch: 360, Treated + Control loss: 0.004647997178835794\n",
      "epoch: 400, Treated + Control loss: 0.017888942966237664\n"
     ]
    }
   ],
   "source": [
    "tuple_control_train = (np_control_x, np_control_ps, np_control_f, np_control_cf)\n",
    "tuple_treated_train = (np_treated_x, np_treated_ps, np_treated_f, np_treated_cf)\n",
    "\n",
    "print(\"Actual Sizes\")\n",
    "print(np_treated_x.shape)\n",
    "print(np_control_x.shape)\n",
    "\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_x, np_treated_ps,\n",
    "                                            np_treated_f, np_treated_cf)\n",
    "\n",
    "train_parameters = {\n",
    "                \"epochs\": 400,\n",
    "                \"lr\": 1e-3,\n",
    "                \"lambda\":1e-4,\n",
    "                \"batch_size\": 100,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_tensor_dataset\": tensor_treated,\n",
    "                \"tuple_control_train\": tuple_control_train\n",
    "    }\n",
    "\n",
    "inference = InferenceNet(input_nodes=25, shared_nodes=200, \n",
    "                         outcome_nodes=100,\n",
    "                         device=device)\n",
    "\n",
    "inference.train(train_parameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Testing phase ------------\n",
      " Treated Statistics ==>\n",
      "(29, 25)\n",
      " Control Statistics ==>\n",
      "(121, 25)\n",
      "(29, 25)\n",
      "(121, 25)\n",
      "Testing using Inference\n",
      "2.549097140895126\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(\"----------- Testing phase ------------\")\n",
    "dL = DataLoader()\n",
    "ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                           np_covariates_Y_test)\n",
    "\n",
    "is_synthetic = False\n",
    "input_nodes = 25\n",
    "\n",
    "\n",
    "\n",
    "data_loader_dict = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                        np_covariates_Y_test,\n",
    "                                                        ps_score_list_test,\n",
    "                                                        is_synthetic)\n",
    "\n",
    "treated_group = data_loader_dict[\"treated_data\"]\n",
    "np_treated_df_X = treated_group[0]\n",
    "np_treated_ps_score = treated_group[1]\n",
    "np_treated_df_Y_f = treated_group[2]\n",
    "np_treated_df_Y_cf = treated_group[3]\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                                     np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "control_group = data_loader_dict[\"control_data\"]\n",
    "np_control_df_X = control_group[0]\n",
    "np_control_ps_score = control_group[1]\n",
    "np_control_df_Y_f = control_group[2]\n",
    "np_control_df_Y_cf = control_group[3]\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "print(np_treated_df_X.shape)\n",
    "print(np_control_df_X.shape)\n",
    "\n",
    "test_parameters = {\n",
    "            \"treated_set\": tensor_treated,\n",
    "            \"control_set\": tensor_control\n",
    "}\n",
    "\n",
    "response_dict = inference.eval(test_parameters, device)\n",
    "err_treated = [ele ** 2 for ele in response_dict[\"treated_err\"]]\n",
    "err_control = [ele ** 2 for ele in response_dict[\"control_err\"]]\n",
    "\n",
    "total_sum = sum(err_treated) + sum(err_control)\n",
    "total_item = len(err_treated) + len(err_control)\n",
    "MSE = total_sum / total_item\n",
    "\n",
    "print(\"Testing using Inference\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional TARNET training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TARNET semi supervised training Unbalanced ###\n",
      "110\n",
      "487\n",
      "(597, 25)\n",
      ".. Training started ..\n",
      "cpu\n",
      "epoch: 40, Treated + Control loss: 2.659998569637537\n",
      "epoch: 80, Treated + Control loss: 4.466428577899933\n",
      "epoch: 120, Treated + Control loss: 0.3149762413231656\n",
      "epoch: 160, Treated + Control loss: 0.2845430513843894\n",
      "epoch: 200, Treated + Control loss: 1.6642653606832027\n",
      "epoch: 240, Treated + Control loss: 0.025484282785328105\n",
      "epoch: 280, Treated + Control loss: 1.0195435918867588\n",
      "epoch: 320, Treated + Control loss: 0.6194570730440319\n",
      "epoch: 360, Treated + Control loss: 1.3314797868952155\n",
      "epoch: 400, Treated + Control loss: 0.13702281238511205\n"
     ]
    }
   ],
   "source": [
    "print(\"### TARNET semi supervised training Unbalanced ###\")\n",
    "np_treated_x, np_treated_ps, np_treated_f, np_treated_cf = data_loader_dict_train[\"treated_data\"]\n",
    "np_control_x, np_control_ps, np_control_f, np_control_cf = data_loader_dict_train[\"control_data\"]\n",
    "\n",
    "t_1 = np.ones(np_treated_x.shape[0])\n",
    "t_0 = np.zeros(np_control_x.shape[0])\n",
    "\n",
    "n_treated = np_treated_x.shape[0]\n",
    "n_control = np_control_x.shape[0]\n",
    "n_total = n_treated + n_control\n",
    "\n",
    "np_train_ss_X = np.concatenate((np_treated_x, np_control_x), axis=0)\n",
    "np_train_ss_ps = np.concatenate((np_treated_ps, np_control_ps), axis=0)\n",
    "np_train_ss_T = np.concatenate((t_1, t_0), axis=0)\n",
    "np_train_ss_f = np.concatenate((np_treated_f, np_control_f), axis=0)\n",
    "np_train_ss_cf = np.concatenate((np_treated_cf, np_control_cf), axis=0)\n",
    "\n",
    "\n",
    "print(np_treated_x.shape[0])\n",
    "print(np_control_x.shape[0])\n",
    "print(np_train_ss_X.shape)\n",
    "\n",
    "train_set = create_tensors_to_train_DCN_semi_supervised((np_train_ss_X, np_train_ss_ps, \n",
    "                                                         np_train_ss_T, np_train_ss_f, \n",
    "                                                         np_train_ss_cf))\n",
    "train_parameters = {\n",
    "                \"epochs\": 400,\n",
    "                \"lr\": 1e-3,\n",
    "                \"lambda\":1e-4,\n",
    "                \"batch_size\": 64,\n",
    "                \"shuffle\": True,\n",
    "                \"tensor_dataset\": train_set\n",
    "    }\n",
    "\n",
    "tarnet = InferenceNet(input_nodes=25, shared_nodes=200, \n",
    "                         outcome_nodes=100,\n",
    "                         device=device)\n",
    "\n",
    "tarnet.train_semi_supervised(train_parameters, n_total, n_treated, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Testing phase ------------\n",
      " Treated Statistics ==>\n",
      "(29, 25)\n",
      " Control Statistics ==>\n",
      "(121, 25)\n",
      "(29, 25)\n",
      "(121, 25)\n",
      "Testing using Inference\n",
      "2.6529256110277672\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "print(\"----------- Testing phase ------------\")\n",
    "dL = DataLoader()\n",
    "ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                           np_covariates_Y_test)\n",
    "\n",
    "is_synthetic = False\n",
    "input_nodes = 25\n",
    "\n",
    " \n",
    "\n",
    "data_loader_dict = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                        np_covariates_Y_test,\n",
    "                                                        ps_score_list_test,\n",
    "                                                        is_synthetic)\n",
    "\n",
    "treated_group = data_loader_dict[\"treated_data\"]\n",
    "np_treated_df_X = treated_group[0]\n",
    "np_treated_ps_score = treated_group[1]\n",
    "np_treated_df_Y_f = treated_group[2]\n",
    "np_treated_df_Y_cf = treated_group[3]\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                                     np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "control_group = data_loader_dict[\"control_data\"]\n",
    "np_control_df_X = control_group[0]\n",
    "np_control_ps_score = control_group[1]\n",
    "np_control_df_Y_f = control_group[2]\n",
    "np_control_df_Y_cf = control_group[3]\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "print(np_treated_df_X.shape)\n",
    "print(np_control_df_X.shape)\n",
    "\n",
    "test_parameters = {\n",
    "            \"treated_set\": tensor_treated,\n",
    "            \"control_set\": tensor_control\n",
    "}\n",
    "\n",
    "response_dict = tarnet.eval(test_parameters, device)\n",
    "err_treated = [ele ** 2 for ele in response_dict[\"treated_err\"]]\n",
    "err_control = [ele ** 2 for ele in response_dict[\"control_err\"]]\n",
    "\n",
    "total_sum = sum(err_treated) + sum(err_control)\n",
    "total_item = len(err_treated) + len(err_control)\n",
    "MSE = total_sum / total_item\n",
    "\n",
    "print(\"Testing using Inference\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCN Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Constants import Constants\n",
    "\n",
    "\n",
    "class DCN_shared(nn.Module):\n",
    "    def __init__(self, input_nodes):\n",
    "        super(DCN_shared, self).__init__()\n",
    "\n",
    "        # shared layer\n",
    "        self.shared1 = nn.Linear(in_features=input_nodes, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.shared1.weight)\n",
    "\n",
    "        self.shared2 = nn.Linear(in_features=200, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.shared2.weight)\n",
    "\n",
    "        self.dropout_2 = nn.Dropout(p=0.2)\n",
    "        self.dropout_5 = nn.Dropout(p=0.5)\n",
    "        self.training_mode = None\n",
    "\n",
    "    def set_train_mode(self, training_mode):\n",
    "        self.training_mode = training_mode\n",
    "\n",
    "    def forward(self, x, ps_score):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        if self.training_mode == Constants.DCN_EVALUATION:\n",
    "            x = self.__eval_net(x)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_PD:\n",
    "            x = self.__train_net_PD(x, ps_score=ps_score)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_5:\n",
    "            x = self.__train_net_constant_dropout(x, ps_score=0.5)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_2:\n",
    "            x = self.__train_net_constant_dropout(x, ps_score=0.2)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_NO_DROPOUT:\n",
    "            x = self.__train_net_no_droput(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __train_net_constant_dropout(self, x, ps_score):\n",
    "        if ps_score == 0.2:\n",
    "            drop_out = self.dropout_2\n",
    "        elif ps_score == 0.5:\n",
    "            drop_out = self.dropout_5\n",
    "\n",
    "        # shared layers\n",
    "        x = F.relu(drop_out(self.shared1(x)))\n",
    "        x = F.relu(drop_out(self.shared2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __train_net_PD(self, x, ps_score):\n",
    "        entropy = Utils.get_shanon_entropy(ps_score.item())\n",
    "        dropout_prob = Utils.get_dropout_probability(entropy, gama=1)\n",
    "\n",
    "        # shared layers\n",
    "        shared_mask = Utils.get_dropout_mask(dropout_prob, self.shared1(x))\n",
    "        x = F.relu(shared_mask * self.shared1(x))\n",
    "        x = F.relu(shared_mask * self.shared2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __train_net_no_droput(self, x):\n",
    "        # shared layers\n",
    "        x = F.relu(self.shared1(x))\n",
    "        x = F.relu(self.shared2(x))\n",
    "        return x\n",
    "\n",
    "    def __eval_net(self, x):\n",
    "        # shared layers\n",
    "        x = F.relu(self.shared1(x))\n",
    "        x = F.relu(self.shared2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DCN_Y1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCN_Y1, self).__init__()\n",
    "\n",
    "        # potential outcome1 Y(1)\n",
    "        self.hidden1_Y1 = nn.Linear(in_features=200, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.hidden1_Y1.weight)\n",
    "\n",
    "        self.hidden2_Y1 = nn.Linear(in_features=200, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.hidden2_Y1.weight)\n",
    "\n",
    "        self.out_Y1 = nn.Linear(in_features=200, out_features=1)\n",
    "        nn.init.xavier_uniform_(self.out_Y1.weight)\n",
    "\n",
    "        self.dropout_2 = nn.Dropout(p=0.2)\n",
    "        self.dropout_5 = nn.Dropout(p=0.5)\n",
    "        self.training_mode = None\n",
    "\n",
    "    def set_train_mode(self, training_mode):\n",
    "        self.training_mode = training_mode\n",
    "\n",
    "    def forward(self, x, ps_score):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        if self.training_mode == Constants.DCN_EVALUATION:\n",
    "            y1 = self.__eval_net(x)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_PD:\n",
    "            y1 = self.__train_net_PD(x, ps_score=ps_score)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_5:\n",
    "            y1 = self.__train_net_constant_dropout(x, ps_score=0.5)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_2:\n",
    "            y1 = self.__train_net_constant_dropout(x, ps_score=0.2)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_NO_DROPOUT:\n",
    "            y1 = self.__train_net_no_droput(x)\n",
    "\n",
    "        return y1\n",
    "\n",
    "    def __train_net_constant_dropout(self, x, ps_score):\n",
    "        if ps_score == 0.2:\n",
    "            drop_out = self.dropout_2\n",
    "        elif ps_score == 0.5:\n",
    "            drop_out = self.dropout_5\n",
    "\n",
    "        # potential outcome1 Y(1)\n",
    "        y1 = F.relu(drop_out(self.hidden1_Y1(x)))\n",
    "        y1 = F.relu(drop_out(self.hidden2_Y1(y1)))\n",
    "        y1 = self.out_Y1(y1)\n",
    "\n",
    "        return y1\n",
    "\n",
    "    def __train_net_PD(self, x, ps_score):\n",
    "        entropy = Utils.get_shanon_entropy(ps_score.item())\n",
    "        dropout_prob = Utils.get_dropout_probability(entropy, gama=1)\n",
    "\n",
    "        # potential outcome1 Y(1)\n",
    "        y1_mask = Utils.get_dropout_mask(dropout_prob, self.hidden1_Y1(x))\n",
    "        y1 = F.relu(y1_mask * self.hidden1_Y1(x))\n",
    "        y1 = F.relu(y1_mask * self.hidden2_Y1(y1))\n",
    "        y1 = self.out_Y1(y1)\n",
    "\n",
    "        return y1\n",
    "\n",
    "    def __train_net_no_droput(self, x):\n",
    "        # potential outcome1 Y(1)\n",
    "        y1 = F.relu(self.hidden1_Y1(x))\n",
    "        y1 = F.relu(self.hidden2_Y1(y1))\n",
    "        y1 = self.out_Y1(y1)\n",
    "\n",
    "        return y1\n",
    "\n",
    "    def __eval_net(self, x):\n",
    "        # potential outcome1 Y(1)\n",
    "        y1 = F.relu(self.hidden1_Y1(x))\n",
    "        y1 = F.relu(self.hidden2_Y1(y1))\n",
    "        y1 = self.out_Y1(y1)\n",
    "\n",
    "        return y1\n",
    "\n",
    "\n",
    "class DCN_Y0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCN_Y0, self).__init__()\n",
    "\n",
    "        # potential outcome1 Y(0)\n",
    "        self.hidden1_Y0 = nn.Linear(in_features=200, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.hidden1_Y0.weight)\n",
    "\n",
    "        self.hidden2_Y0 = nn.Linear(in_features=200, out_features=200)\n",
    "        nn.init.xavier_uniform_(self.hidden2_Y0.weight)\n",
    "\n",
    "        self.out_Y0 = nn.Linear(in_features=200, out_features=1)\n",
    "        nn.init.xavier_uniform_(self.out_Y0.weight)\n",
    "\n",
    "        self.dropout_2 = nn.Dropout(p=0.2)\n",
    "        self.dropout_5 = nn.Dropout(p=0.5)\n",
    "        self.training_mode = None\n",
    "\n",
    "    def set_train_mode(self, training_mode):\n",
    "        self.training_mode = training_mode\n",
    "        \n",
    "\n",
    "    def forward(self, x, ps_score):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.float().cuda()\n",
    "        else:\n",
    "            x = x.float()\n",
    "\n",
    "        if self.training_mode == Constants.DCN_EVALUATION:\n",
    "            y0 = self.__eval_net(x)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_PD:\n",
    "            y0 = self.__train_net_PD(x, ps_score=ps_score)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_5:\n",
    "            y0 = self.__train_net_constant_dropout(x, ps_score=0.5)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_CONSTANT_DROPOUT_2:\n",
    "            y0 = self.__train_net_constant_dropout(x, ps_score=0.2)\n",
    "        elif self.training_mode == Constants.DCN_TRAIN_NO_DROPOUT:\n",
    "            y0 = self.__train_net_no_droput(x)\n",
    "\n",
    "        return y0\n",
    "\n",
    "    def __train_net_constant_dropout(self, x, ps_score):\n",
    "        if ps_score == 0.2:\n",
    "            drop_out = self.dropout_2\n",
    "        elif ps_score == 0.5:\n",
    "            drop_out = self.dropout_5\n",
    "\n",
    "        # potential outcome1 Y(0)\n",
    "        y0 = F.relu(drop_out(self.hidden1_Y0(x)))\n",
    "        y0 = F.relu(drop_out(self.hidden2_Y0(y0)))\n",
    "        y0 = self.out_Y0(y0)\n",
    "\n",
    "        return y0\n",
    "\n",
    "    def __train_net_PD(self, x, ps_score):\n",
    "        entropy = Utils.get_shanon_entropy(ps_score.item())\n",
    "        dropout_prob = Utils.get_dropout_probability(entropy, gama=1)\n",
    "\n",
    "        # potential outcome1 Y(0)\n",
    "        y0_mask = Utils.get_dropout_mask(dropout_prob, self.hidden1_Y0(x))\n",
    "        y0 = F.relu(y0_mask * self.hidden1_Y0(x))\n",
    "        y0 = F.relu(y0_mask * self.hidden2_Y0(y0))\n",
    "        y0 = self.out_Y0(y0)\n",
    "\n",
    "        return y0\n",
    "\n",
    "    def __train_net_no_droput(self, x):\n",
    "        # potential outcome1 Y(0)\n",
    "        y0 = F.relu(self.hidden1_Y0(x))\n",
    "        y0 = F.relu(self.hidden2_Y0(y0))\n",
    "        y0 = self.out_Y0(y0)\n",
    "\n",
    "        return y0\n",
    "\n",
    "    def __eval_net(self, x):\n",
    "        # potential outcome1 Y(0)\n",
    "        y0 = F.relu(self.hidden1_Y0(x))\n",
    "        y0 = F.relu(self.hidden2_Y0(y0))\n",
    "        y0 = self.out_Y0(y0)\n",
    "\n",
    "        return y0\n",
    "\n",
    "\n",
    "####################################\n",
    "\n",
    "class DCN_network_2:\n",
    "    def __init__(self, input_nodes, training_mode, device):\n",
    "        self.dcn_shared = DCN_shared(input_nodes=input_nodes, ).to(device)\n",
    "        self.dcn_y1 = DCN_Y1().to(device)\n",
    "        self.dcn_y0 = DCN_Y0().to(device)\n",
    "\n",
    "    def train(self, train_parameters, device, train_mode=Constants.DCN_TRAIN_PD):\n",
    "        epochs = train_parameters[\"epochs\"]\n",
    "        treated_batch_size = train_parameters[\"treated_batch_size\"]\n",
    "        control_batch_size = train_parameters[\"control_batch_size\"]\n",
    "        lr = train_parameters[\"lr\"]\n",
    "        shuffle = train_parameters[\"shuffle\"]\n",
    "        treated_set_train = train_parameters[\"treated_set_train\"]\n",
    "        control_set_train = train_parameters[\"control_set_train\"]\n",
    "\n",
    "        self.dcn_shared.set_train_mode(training_mode=train_mode)\n",
    "        self.dcn_y1.set_train_mode(training_mode=train_mode)\n",
    "        self.dcn_y0.set_train_mode(training_mode=train_mode)\n",
    "\n",
    "        treated_data_loader_train = torch.utils.data.DataLoader(treated_set_train,\n",
    "                                                                batch_size=treated_batch_size,\n",
    "                                                                shuffle=shuffle,\n",
    "                                                                num_workers=1)\n",
    "\n",
    "        control_data_loader_train = torch.utils.data.DataLoader(control_set_train,\n",
    "                                                                batch_size=control_batch_size,\n",
    "                                                                shuffle=shuffle,\n",
    "                                                                num_workers=1)\n",
    "\n",
    "        optimizer_shared = optim.Adam(self.dcn_shared.parameters(), lr=lr)\n",
    "        optimizer_y1 = optim.Adam(self.dcn_y1.parameters(), lr=lr)\n",
    "        optimizer_y0 = optim.Adam(self.dcn_y0.parameters(), lr=lr)\n",
    "        lossF = nn.MSELoss()\n",
    "\n",
    "        min_loss = 100000.0\n",
    "        dataset_loss = 0.0\n",
    "        print(\".. Training started ..\")\n",
    "        print(device)\n",
    "        for epoch in range(epochs):\n",
    "            self.dcn_shared.train()\n",
    "            self.dcn_y1.train()\n",
    "            self.dcn_y0.train()\n",
    "            total_loss = 0\n",
    "            train_set_size = 0\n",
    "\n",
    "            if epoch % 2 == 0:\n",
    "                dataset_loss = 0\n",
    "                # train treated\n",
    "                for batch in treated_data_loader_train:\n",
    "                    covariates_X, ps_score, y_f, y_cf = batch\n",
    "                    covariates_X = covariates_X.to(device)\n",
    "                    ps_score = ps_score.squeeze().to(device)\n",
    "                    train_set_size += covariates_X.size(0)\n",
    "                    y1_hat = self.dcn_y1(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "                    if torch.cuda.is_available():\n",
    "                        loss = lossF(y1_hat.float().cuda(),\n",
    "                                     y_f.float().cuda()).to(device)\n",
    "                    else:\n",
    "                        loss = lossF(y1_hat.float(),\n",
    "                                     y_f.float()).to(device)\n",
    "\n",
    "                    optimizer_shared.zero_grad()\n",
    "                    optimizer_y1.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer_shared.step()\n",
    "                    optimizer_y1.step()\n",
    "                    total_loss += loss.item()\n",
    "                dataset_loss = total_loss\n",
    "\n",
    "            elif epoch % 2 == 1:\n",
    "                # train control\n",
    "\n",
    "                for batch in control_data_loader_train:\n",
    "                    covariates_X, ps_score, y_f, y_cf = batch\n",
    "                    covariates_X = covariates_X.to(device)\n",
    "                    ps_score = ps_score.squeeze().to(device)\n",
    "\n",
    "                    train_set_size += covariates_X.size(0)\n",
    "                    y0_hat = self.dcn_y0(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "                    if torch.cuda.is_available():\n",
    "                        loss = lossF(y0_hat.float().cuda(),\n",
    "                                     y_f.float().cuda()).to(device)\n",
    "                    else:\n",
    "                        loss = lossF(y0_hat.float(),\n",
    "                                     y_f.float()).to(device)\n",
    "                    optimizer_shared.zero_grad()\n",
    "                    optimizer_y0.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer_shared.step()\n",
    "                    optimizer_y0.step()\n",
    "                    total_loss += loss.item()\n",
    "                    total_loss += loss.item()\n",
    "                dataset_loss = dataset_loss + total_loss\n",
    "\n",
    "            if epoch % 10 == 9:\n",
    "                print(\"epoch: {0}, Treated + Control loss: {1}\".format(epoch, dataset_loss))\n",
    "\n",
    "    def eval(self, eval_parameters, device, input_nodes, train_mode):\n",
    "        treated_set = eval_parameters[\"treated_set\"]\n",
    "        control_set = eval_parameters[\"control_set\"]\n",
    "\n",
    "        self.dcn_shared.eval()\n",
    "        self.dcn_y1.eval()\n",
    "        self.dcn_y0.eval()\n",
    "        treated_data_loader = torch.utils.data.DataLoader(treated_set,\n",
    "                                                          shuffle=False, num_workers=1)\n",
    "        control_data_loader = torch.utils.data.DataLoader(control_set,\n",
    "                                                          shuffle=False, num_workers=1)\n",
    "\n",
    "        err_treated_list = []\n",
    "        err_control_list = []\n",
    "        true_ITE_list = []\n",
    "        predicted_ITE_list = []\n",
    "\n",
    "        ITE_dict_list = []\n",
    "\n",
    "        for batch in treated_data_loader:\n",
    "            covariates_X, ps_score, y_f, y_cf = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "            ps_score = ps_score.squeeze().to(device)\n",
    "            y1_hat = self.dcn_y1(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            y0_hat = self.dcn_y0(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            predicted_ITE = y1_hat - y0_hat\n",
    "\n",
    "            true_ITE = y_f - y_cf\n",
    "            if torch.cuda.is_available():\n",
    "                diff = true_ITE.float().cuda() - predicted_ITE.float().cuda()\n",
    "            else:\n",
    "                diff = true_ITE.float() - predicted_ITE.float()\n",
    "\n",
    "            ITE_dict_list.append(self.create_ITE_Dict(covariates_X,\n",
    "                                                      ps_score.item(), y_f.item(),\n",
    "                                                      y_cf.item(),\n",
    "                                                      true_ITE.item(),\n",
    "                                                      predicted_ITE.item(),\n",
    "                                                      diff.item()))\n",
    "            err_treated_list.append(diff.item())\n",
    "            true_ITE_list.append(true_ITE.item())\n",
    "            predicted_ITE_list.append(predicted_ITE.item())\n",
    "\n",
    "        for batch in control_data_loader:\n",
    "            covariates_X, ps_score, y_f, y_cf = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "            ps_score = ps_score.squeeze().to(device)\n",
    "            y1_hat = self.dcn_y1(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            y0_hat = self.dcn_y0(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            predicted_ITE = y1_hat - y0_hat\n",
    "            true_ITE = y_cf - y_f\n",
    "            if torch.cuda.is_available():\n",
    "                diff = true_ITE.float().cuda() - predicted_ITE.float().cuda()\n",
    "            else:\n",
    "                diff = true_ITE.float() - predicted_ITE.float()\n",
    "\n",
    "            ITE_dict_list.append(self.create_ITE_Dict(covariates_X,\n",
    "                                                      ps_score.item(), y_f.item(),\n",
    "                                                      y_cf.item(),\n",
    "                                                      true_ITE.item(),\n",
    "                                                      predicted_ITE.item(),\n",
    "                                                      diff.item()))\n",
    "            err_control_list.append(diff.item())\n",
    "            true_ITE_list.append(true_ITE.item())\n",
    "            predicted_ITE_list.append(predicted_ITE.item())\n",
    "\n",
    "        # print(err_treated_list)\n",
    "        # print(err_control_list)\n",
    "        return {\n",
    "            \"treated_err\": err_treated_list,\n",
    "            \"control_err\": err_control_list,\n",
    "            \"true_ITE\": true_ITE_list,\n",
    "            \"predicted_ITE\": predicted_ITE_list,\n",
    "            \"ITE_dict_list\": ITE_dict_list\n",
    "        }\n",
    "\n",
    "    def eval_semi_supervised(self, eval_parameters, device, input_nodes, train_mode, treated_flag):\n",
    "        eval_set = eval_parameters[\"eval_set\"]\n",
    "\n",
    "        self.dcn_shared.eval()\n",
    "        self.dcn_y1.eval()\n",
    "        self.dcn_y0.eval()\n",
    "        treated_data_loader = torch.utils.data.DataLoader(eval_set,\n",
    "                                                          shuffle=False, num_workers=1)\n",
    "\n",
    "        y_f_list = []\n",
    "        y_cf_list = []\n",
    "\n",
    "        for batch in treated_data_loader:\n",
    "            covariates_X, ps_score = batch\n",
    "            covariates_X = covariates_X.to(device)\n",
    "            ps_score = ps_score.squeeze().to(device)\n",
    "            y1_hat = self.dcn_y1(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            y0_hat = self.dcn_y0(self.dcn_shared(covariates_X, ps_score), ps_score)\n",
    "            if treated_flag:\n",
    "                y_f_list.append(y1_hat.item())\n",
    "                y_cf_list.append(y0_hat.item())\n",
    "            else:\n",
    "                y_f_list.append(y0_hat.item())\n",
    "                y_cf_list.append(y1_hat.item())\n",
    "\n",
    "        return {\n",
    "            \"y_f_list\": np.array(y_f_list),\n",
    "            \"y_cf_list\": np.array(y_cf_list)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def create_ITE_Dict(covariates_X, ps_score, y_f, y_cf, true_ITE,\n",
    "                        predicted_ITE, diff):\n",
    "        result_dict = OrderedDict()\n",
    "        covariate_list = [element.item() for element in covariates_X.flatten()]\n",
    "        idx = 0\n",
    "        for item in covariate_list:\n",
    "            idx += 1\n",
    "            result_dict[\"X\" + str(idx)] = item\n",
    "\n",
    "        result_dict[\"ps_score\"] = ps_score\n",
    "        result_dict[\"factual\"] = y_f\n",
    "        result_dict[\"counter_factual\"] = y_cf\n",
    "        result_dict[\"true_ITE\"] = true_ITE\n",
    "        result_dict[\"predicted_ITE\"] = predicted_ITE\n",
    "        result_dict[\"diff\"] = diff\n",
    "\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi supervised PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_treated = Utils.create_tensors_to_train_DCN(data_loader_dict_train[\"treated_data\"], dL)\n",
    "t_control =  Utils.create_tensors_to_train_DCN(data_loader_dict_train[\"control_data\"], dL)\n",
    "\n",
    "print(data_loader_dict_train[\"treated_data\"][0].shape)\n",
    "print(data_loader_dict_train[\"control_data\"][0].shape)\n",
    "\n",
    "train_mode = Constants.DCN_TRAIN_PD\n",
    "DCN_train_parameters = {\n",
    "                \"epochs\": epochs,\n",
    "                \"lr\": lr,\n",
    "                \"treated_batch_size\": 1,\n",
    "                \"control_batch_size\": 1,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_set_train\": t_treated,\n",
    "                \"control_set_train\": t_control,\n",
    "                \"input_nodes\": input_nodes\n",
    "    }\n",
    "\n",
    "            # train DCN network\n",
    "dcn_ss_pd = DCN_network_2(input_nodes, train_mode, device )\n",
    "dcn_ss_pd.train(DCN_train_parameters, device, train_mode=train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_list_treated_np = np.array(ps_score_list_treated)\n",
    "eval_set = convert_to_tensor_DCN_PS(treated_generated.detach(), ps_score_list_treated_np)\n",
    "\n",
    "DCN_test_parameters = {\n",
    "            \"eval_set\": eval_set\n",
    "}\n",
    "treated_gen_y = dcn_ss_pd.eval_semi_supervised(DCN_test_parameters, device, input_nodes,\n",
    "                                 Constants.DCN_EVALUATION, treated_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised No PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_np_control_matched_X = tuple_matched_control[0]\n",
    "_np_ps_score_list_control_matched = tuple_matched_control[1]\n",
    "_np_control_matched_f = tuple_matched_control[2]\n",
    "_np_control_matched_cf = tuple_matched_control[3]\n",
    "\n",
    "\n",
    "_tensor_control = Utils.convert_to_tensor_DCN(_np_control_matched_X, _np_ps_score_list_control_matched,\n",
    "                                            _np_control_matched_f, _np_control_matched_cf)\n",
    "\n",
    "_np_original_X = tuple_treated[0]\n",
    "_np_original_ps_score = tuple_treated[1]\n",
    "_np_original_Y_f = tuple_treated[2]\n",
    "_np_original_Y_cf = tuple_treated[3]\n",
    "\n",
    "print(\"Actual Sizes\")\n",
    "print(_np_control_matched_X.shape)\n",
    "print(_np_original_X.shape)\n",
    "\n",
    "_tensor_treated = Utils.convert_to_tensor_DCN(_np_original_X, _np_original_ps_score,\n",
    "                                            _np_original_Y_cf, _np_original_Y_f)\n",
    "\n",
    "train_mode = Constants.DCN_TRAIN_NO_DROPOUT\n",
    "DCN_train_parameters = {\n",
    "                \"epochs\": epochs,\n",
    "                \"lr\": lr,\n",
    "                \"treated_batch_size\": 1,\n",
    "                \"control_batch_size\": 1,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_set_train\": _tensor_treated,\n",
    "                \"control_set_train\": _tensor_control,\n",
    "                \"input_nodes\": input_nodes\n",
    "    }\n",
    "\n",
    "# train DCN network\n",
    "dcn_ss_no_pd = DCN_network_2(input_nodes, train_mode, device )\n",
    "dcn_ss_no_pd.train(DCN_train_parameters, device, train_mode=train_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_list_treated_np = np.array(ps_score_list_treated)\n",
    "eval_set = convert_to_tensor_DCN_PS(treated_generated.detach(), ps_score_list_treated_np)\n",
    "\n",
    "DCN_test_parameters = {\n",
    "            \"eval_set\": eval_set\n",
    "}\n",
    "treated_gen_y = dcn_ss_no_pd.eval_semi_supervised(DCN_test_parameters, device, input_nodes,\n",
    "                                 Constants.DCN_EVALUATION, treated_flag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_treated_generated = treated_generated.detach().numpy()\n",
    "np_ps_score_list_gen_treated = ps_score_list_treated_np\n",
    "np_treated_gen_f = Utils.convert_to_col_vector(treated_gen_y[\"y_f_list\"])\n",
    "np_treated_gen_cf = Utils.convert_to_col_vector(treated_gen_y[\"y_cf_list\"])\n",
    "\n",
    "print(np_treated_gen_f.shape)\n",
    "\n",
    "np_original_X = tuple_treated[0]\n",
    "np_original_ps_score = tuple_treated[1]\n",
    "np_original_Y_f = tuple_treated[2]\n",
    "np_original_Y_cf = tuple_treated[3]\n",
    "\n",
    "print(np_original_Y_f.shape)\n",
    "\n",
    "np_treated_x = np.concatenate((np_treated_generated, np_original_X), axis=0)\n",
    "np_treated_ps = np.concatenate((np_ps_score_list_gen_treated, np_original_ps_score), axis=0)\n",
    "np_treated_f = np.concatenate((np_treated_gen_f, np_original_Y_f), axis=0)\n",
    "np_treated_cf = np.concatenate((np_treated_gen_cf, np_original_Y_cf), axis=0)\n",
    "\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_x, np_treated_ps,\n",
    "                                            np_treated_f, np_treated_cf)\n",
    "\n",
    "np_treated_x.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_control_unmatched_X = tuple_unmatched_control[0]\n",
    "np_ps_score_list_control_unmatched = tuple_unmatched_control[1]\n",
    "np_control_unmatched_f = tuple_unmatched_control[2]\n",
    "np_control_unmatched_cf = tuple_unmatched_control[3]\n",
    "\n",
    "np_control_matched_X = tuple_matched_control[0]\n",
    "np_ps_score_list_control_matched = tuple_matched_control[1]\n",
    "np_control_matched_f = tuple_matched_control[2]\n",
    "np_control_matched_cf = tuple_matched_control[3]\n",
    "\n",
    "print(np_control_unmatched_cf.shape)\n",
    "print(np_control_matched_cf.shape)\n",
    "\n",
    "np_control_x = np.concatenate((np_control_unmatched_X, np_control_matched_X), axis=0)\n",
    "np_control_ps = np.concatenate((np_ps_score_list_control_unmatched, np_ps_score_list_control_matched), axis=0)\n",
    "np_control_f = np.concatenate((np_control_unmatched_f, np_control_matched_f), axis=0)\n",
    "np_control_cf = np.concatenate((np_control_unmatched_cf, np_control_matched_cf), axis=0)\n",
    "\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_x, np_control_ps,\n",
    "                                            np_control_f, np_control_cf)\n",
    "\n",
    "\n",
    "np_control_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### DCN training using all dataset no PD ###\")\n",
    "\n",
    "DCN_train_parameters = {\n",
    "                \"epochs\": epochs,\n",
    "                \"lr\": lr,\n",
    "                \"treated_batch_size\": 1,\n",
    "                \"control_batch_size\": 1,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_set_train\": tensor_treated,\n",
    "                \"control_set_train\": tensor_control,\n",
    "                \"input_nodes\": input_nodes\n",
    "    }\n",
    "\n",
    "train_mode = Constants.DCN_TRAIN_NO_DROPOUT\n",
    "dcn_pd = DCN_network_2(input_nodes, train_mode, device )\n",
    "dcn_pd.train(DCN_train_parameters, device, train_mode=train_mode)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "print(\"----------- Testing phase ------------\")\n",
    "dL = DataLoader()\n",
    "ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                           np_covariates_Y_test)\n",
    "\n",
    "is_synthetic = False\n",
    "input_nodes = 25\n",
    "\n",
    "        # get propensity scores using NN\n",
    "ps_net_NN = Propensity_socre_network()\n",
    "ps_eval_parameters_NN = {\n",
    "            \"eval_set\": ps_test_set,\n",
    "            \"model_path\": Constants.PROP_SCORE_NN_MODEL_PATH\n",
    "                .format(iter_id, Constants.PROP_SCORE_NN_EPOCHS, Constants.PROP_SCORE_NN_LR),\n",
    "            \"input_nodes\": input_nodes\n",
    "}\n",
    "ps_score_list_NN = ps_net_NN.eval(ps_eval_parameters_NN, device, phase=\"eval\")\n",
    "\n",
    "data_loader_dict = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                        np_covariates_Y_test,\n",
    "                                                        ps_score_list_NN,\n",
    "                                                        is_synthetic)\n",
    "\n",
    "\n",
    "treated_group = data_loader_dict[\"treated_data\"]\n",
    "np_treated_df_X = treated_group[0]\n",
    "np_treated_ps_score = treated_group[1]\n",
    "np_treated_df_Y_f = treated_group[2]\n",
    "np_treated_df_Y_cf = treated_group[3]\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                                     np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "control_group = data_loader_dict[\"control_data\"]\n",
    "np_control_df_X = control_group[0]\n",
    "np_control_ps_score = control_group[1]\n",
    "np_control_df_Y_f = control_group[2]\n",
    "np_control_df_Y_cf = control_group[3]\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "DCN_test_parameters = {\n",
    "            \"treated_set\": tensor_treated,\n",
    "            \"control_set\": tensor_control\n",
    "}\n",
    "\n",
    "response_dict = dcn_pd.eval(DCN_test_parameters, device, input_nodes,\n",
    "                                 Constants.DCN_EVALUATION)\n",
    "err_treated = [ele ** 2 for ele in response_dict[\"treated_err\"]]\n",
    "err_control = [ele ** 2 for ele in response_dict[\"control_err\"]]\n",
    "\n",
    "total_sum = sum(err_treated) + sum(err_control)\n",
    "total_item = len(err_treated) + len(err_control)\n",
    "MSE = total_sum / total_item\n",
    "\n",
    "print(\"PSM\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCN_PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_treated = Utils.create_tensors_to_train_DCN(data_loader_dict_train[\"treated_data\"], dL)\n",
    "t_control =  Utils.create_tensors_to_train_DCN(data_loader_dict_train[\"control_data\"], dL)\n",
    "\n",
    "print(data_loader_dict_train[\"treated_data\"][0].shape)\n",
    "print(data_loader_dict_train[\"control_data\"][0].shape)\n",
    "\n",
    "train_mode = Constants.DCN_TRAIN_PD\n",
    "DCN_train_parameters = {\n",
    "                \"epochs\": epochs,\n",
    "                \"lr\": lr,\n",
    "                \"treated_batch_size\": 1,\n",
    "                \"control_batch_size\": 1,\n",
    "                \"shuffle\": True,\n",
    "                \"treated_set_train\": t_treated,\n",
    "                \"control_set_train\": t_control,\n",
    "                \"input_nodes\": input_nodes\n",
    "    }\n",
    "\n",
    "            # train DCN network\n",
    "dcn_ss_pd = DCN_network_2(input_nodes, train_mode, device )\n",
    "dcn_ss_pd.train(DCN_train_parameters, device, train_mode=train_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "print(\"----------- Testing phase ------------\")\n",
    "dL = DataLoader()\n",
    "ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                           np_covariates_Y_test)\n",
    "\n",
    "is_synthetic = False\n",
    "input_nodes = 25\n",
    "\n",
    "        # get propensity scores using NN\n",
    "ps_net_NN = Propensity_socre_network()\n",
    "ps_eval_parameters_NN = {\n",
    "            \"eval_set\": ps_test_set,\n",
    "            \"model_path\": Constants.PROP_SCORE_NN_MODEL_PATH\n",
    "                .format(iter_id, Constants.PROP_SCORE_NN_EPOCHS, Constants.PROP_SCORE_NN_LR),\n",
    "            \"input_nodes\": input_nodes\n",
    "}\n",
    "ps_score_list_NN = ps_net_NN.eval(ps_eval_parameters_NN, device, phase=\"eval\")\n",
    "\n",
    "data_loader_dict = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                        np_covariates_Y_test,\n",
    "                                                        ps_score_list_NN,\n",
    "                                                        is_synthetic)\n",
    "\n",
    "\n",
    "treated_group = data_loader_dict[\"treated_data\"]\n",
    "np_treated_df_X = treated_group[0]\n",
    "np_treated_ps_score = treated_group[1]\n",
    "np_treated_df_Y_f = treated_group[2]\n",
    "np_treated_df_Y_cf = treated_group[3]\n",
    "tensor_treated = Utils.convert_to_tensor_DCN(np_treated_df_X, np_treated_ps_score,\n",
    "                                                     np_treated_df_Y_f, np_treated_df_Y_cf)\n",
    "\n",
    "control_group = data_loader_dict[\"control_data\"]\n",
    "np_control_df_X = control_group[0]\n",
    "np_control_ps_score = control_group[1]\n",
    "np_control_df_Y_f = control_group[2]\n",
    "np_control_df_Y_cf = control_group[3]\n",
    "tensor_control = Utils.convert_to_tensor_DCN(np_control_df_X, np_control_ps_score,\n",
    "                                                     np_control_df_Y_f, np_control_df_Y_cf)\n",
    "\n",
    "DCN_test_parameters = {\n",
    "            \"treated_set\": tensor_treated,\n",
    "            \"control_set\": tensor_control\n",
    "}\n",
    "\n",
    "response_dict = dcn_ss_pd.eval(DCN_test_parameters, device, input_nodes,\n",
    "                                 Constants.DCN_EVALUATION)\n",
    "err_treated = [ele ** 2 for ele in response_dict[\"treated_err\"]]\n",
    "err_control = [ele ** 2 for ele in response_dict[\"control_err\"]]\n",
    "\n",
    "total_sum = sum(err_treated) + sum(err_control)\n",
    "total_item = len(err_treated) + len(err_control)\n",
    "MSE = total_sum / total_item\n",
    "\n",
    "print(\"PSM\")\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
