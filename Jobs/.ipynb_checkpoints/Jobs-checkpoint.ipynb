{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from Utils import Utils\n",
    "from Constants import Constants\n",
    "from Propensity_socre_network import Propensity_socre_network\n",
    "from Utils import Utils\n",
    "from PS_Manager import PS_Manager\n",
    "from PS_Treated_Generator import PS_Treated_Generator\n",
    "\n",
    "from GAN import Generator, Discriminator\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from GAN_Manager import GAN_Manager\n",
    "from Utils import Utils\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from torch.autograd.variable import Variable\n",
    "from collections import OrderedDict\n",
    "from scipy.special import expit\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "from dataloader import DataLoader\n",
    "from DCN_Experiments import DCN_Experiments\n",
    "from Metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_ps_model(ps_model_type, iter_id,\n",
    "                   input_nodes, device,\n",
    "                   np_covariates_X_train, \n",
    "                   np_covariates_X_test, \n",
    "                   np_covariates_Y_train,\n",
    "                   np_covariates_Y_test, dL):\n",
    "    ps_train_set = dL.convert_to_tensor(np_covariates_X_train, np_covariates_Y_train)\n",
    "    ps_test_set = dL.convert_to_tensor(np_covariates_X_test,\n",
    "                                            np_covariates_Y_test)\n",
    "    ps_manager = PS_Manager()\n",
    "    if ps_model_type == Constants.PS_MODEL_NN:\n",
    "        return ps_manager.get_propensity_scores(ps_train_set,\n",
    "                                                    ps_test_set, iter_id,\n",
    "                                                    input_nodes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_nodes = 17\n",
    "device = Utils.get_device()\n",
    "ps_model_type=Constants.PS_MODEL_NN\n",
    "train_path = \"Dataset/jobs_DW_bin.new.10.train.npz\"\n",
    "test_path = \"Dataset/jobs_DW_bin.new.10.test.npz\"\n",
    "split_size = 0.8\n",
    "dL = DataLoader()\n",
    "\n",
    "Constants.PROP_SCORE_NN_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Train Statistics:\n",
      "(2570, 19)\n",
      "(2570, 1)\n",
      " Numpy Test Statistics:\n",
      "(642, 19)\n",
      "(642, 1)\n"
     ]
    }
   ],
   "source": [
    "np_covariates_X_train, np_covariates_X_test, np_covariates_T_train, \\\n",
    "        np_covariates_T_test \\\n",
    "            = dL.load_train_test_jobs(train_path, test_path, iter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Propensity Score neural net Training ###############\n",
      ".. PS Training started ..\n",
      "Epoch: 50, loss: 13.957078225910664, correct: 2347/2570, accuracy: 0.9132295719844358\n",
      "Epoch: 100, loss: 12.979373145848513, correct: 2371/2570, accuracy: 0.9225680933852141\n",
      "Epoch: 150, loss: 12.010436907410622, correct: 2381/2570, accuracy: 0.9264591439688716\n",
      "Training Completed..\n"
     ]
    }
   ],
   "source": [
    "ps_score_list_train, ps_score_list_test, ps_model = __get_ps_model(ps_model_type, \n",
    "                                                                   1, input_nodes,\n",
    "                                                                device, \n",
    "                                                                np_covariates_X_train, \n",
    "                                                                np_covariates_X_test, \n",
    "                                                                np_covariates_T_train,\n",
    "                                                                np_covariates_T_test,\n",
    "                                                                dL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2570\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "print(len(ps_score_list_train))\n",
    "print(len(ps_score_list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--->>Train size: \n",
      "Big X: (2570, 21)\n",
      " Treated Statistics ==>\n",
      "(237, 17)\n",
      " Control Statistics ==>\n",
      "(2333, 17)\n",
      "--->>Test size: \n",
      "Big X: (642, 21)\n",
      " Treated Statistics ==>\n",
      "(60, 17)\n",
      " Control Statistics ==>\n",
      "(582, 17)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"--->>Train size: \")\n",
    "data_loader_dict_train = dL.prepare_tensor_for_DCN(np_covariates_X_train,\n",
    "                                                        np_covariates_T_train,\n",
    "                                                        ps_score_list_train,\n",
    "                                                        False)\n",
    "print(\"--->>Test size: \")\n",
    "data_loader_dict_test = dL.prepare_tensor_for_DCN(np_covariates_X_test,\n",
    "                                                      np_covariates_T_test,\n",
    "                                                      ps_score_list_test,\n",
    "                                                      False)\n",
    "print(len(data_loader_dict_train[\"treated_data\"]))\n",
    "\n",
    "tensor_treated_train_original = \\\n",
    "                Utils.create_tensors_from_tuple(data_loader_dict_train[\"treated_data\"])\n",
    "tensor_control_train_original = \\\n",
    "                Utils.create_tensors_from_tuple(data_loader_dict_test[\"control_data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Matched Control: (237, 17)\n",
      "-> UnMatched Control: (2205, 17)\n",
      "-> GAN training started\n",
      "Epoch: 1000, D_loss: 32.7128946185112, D_score_real: 23.75793957710266, D_score_Fake: 11.37055292725563, G_loss: 41.03593552112579, Prop_loss: 110.76152908802032\n",
      "Epoch: 2000, D_loss: 30.848858952522278, D_score_real: 24.5241539478302, D_score_Fake: 10.49499523639679, G_loss: 44.557498812675476, Prop_loss: 61.76901459693909\n",
      "Epoch: 3000, D_loss: 32.90187919139862, D_score_real: 23.768618285655975, D_score_Fake: 11.267085611820221, G_loss: 42.22055399417877, Prop_loss: 81.71781003475189\n",
      "Epoch: 4000, D_loss: 31.761606335639954, D_score_real: 24.31711834669113, D_score_Fake: 10.861313104629517, G_loss: 42.7986261844635, Prop_loss: 51.57673639059067\n",
      "Epoch: 5000, D_loss: 31.677600860595703, D_score_real: 24.180280685424805, D_score_Fake: 10.598519057035446, G_loss: 44.0903936624527, Prop_loss: 46.65553414821625\n",
      "Epoch: 6000, D_loss: 30.43159329891205, D_score_real: 24.641621947288513, D_score_Fake: 10.398718237876892, G_loss: 43.89206504821777, Prop_loss: 69.94800078868866\n",
      "Epoch: 7000, D_loss: 30.21762043237686, D_score_real: 24.728329181671143, D_score_Fake: 10.314184844493866, G_loss: 43.90014684200287, Prop_loss: 75.88977825641632\n",
      "Epoch: 8000, D_loss: 29.788300931453705, D_score_real: 24.867778837680817, D_score_Fake: 10.235538631677628, G_loss: 45.05746150016785, Prop_loss: 48.691085517406464\n",
      "Epoch: 9000, D_loss: 30.141035437583923, D_score_real: 24.887092351913452, D_score_Fake: 10.437909990549088, G_loss: 44.29341661930084, Prop_loss: 60.91740506887436\n",
      "Epoch: 10000, D_loss: 29.366766214370728, D_score_real: 25.0127854347229, D_score_Fake: 10.115003615617752, G_loss: 45.700196743011475, Prop_loss: 60.58573669195175\n",
      "-> GAN training completed\n",
      "----------------------------------------\n",
      "----->>> Semi supervised training started for DCN <<<-----\n",
      "epoch: 100, Treated + Control loss: 105.25211579157076\n",
      "epoch: 200, Treated + Control loss: 86.349922121976\n",
      "epoch: 300, Treated + Control loss: 90.07943135950924\n",
      "epoch: 400, Treated + Control loss: 77.63751235601072\n",
      "---> Semi supervised training completed...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_t = PS_Treated_Generator(data_loader_dict_train, ps_model)\n",
    "balanced_dataset_dict = ps_t.simulate_treated_semi_supervised(input_nodes, iter_id, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "###### Model 1: DCN - PD Supervised Training started ######\n",
      "Train_mode: train_PD\n",
      "epoch: 100, Treated + Control loss: 100.9043382124537\n",
      "epoch: 200, Treated + Control loss: 79.30706841783076\n",
      "epoch: 300, Treated + Control loss: 69.57941165697125\n",
      "epoch: 400, Treated + Control loss: 58.21852614075187\n",
      "----------------------------------------\n",
      "###### Model 2: DCN PM GAN - No dropout - Supervised Training started ######\n",
      "Train_mode: train_with_no_dropout\n",
      "epoch: 100, Treated + Control loss: 378.2583334859115\n",
      "epoch: 200, Treated + Control loss: 276.443437486341\n",
      "epoch: 300, Treated + Control loss: 212.0829366477054\n",
      "epoch: 400, Treated + Control loss: 211.10518839375973\n",
      "###### Model 3: DCN PM GAN - Probability 0.2 - Supervised Training started ######\n",
      "Train_mode: train_constant_dropout_2\n",
      "epoch: 100, Treated + Control loss: 527.9360118243728\n",
      "epoch: 200, Treated + Control loss: 485.9896758321023\n",
      "epoch: 300, Treated + Control loss: 437.57827957144605\n",
      "epoch: 400, Treated + Control loss: 411.1539789093993\n",
      "###### Model 4: DCN PM GAN - Probability 0.5 - Supervised Training started ######\n",
      "Train_mode: train_constant_dropout_5\n",
      "epoch: 100, Treated + Control loss: 608.6349539455196\n",
      "epoch: 200, Treated + Control loss: 609.9134858064097\n",
      "epoch: 300, Treated + Control loss: 575.2903085467547\n",
      "epoch: 400, Treated + Control loss: 592.3622178995739\n"
     ]
    }
   ],
   "source": [
    "tensor_treated_balanced_dcn = balanced_dataset_dict[\"tensor_treated_balanced_dcn\"]\n",
    "tensor_control_balanced_dcn = balanced_dataset_dict[\"tensor_control_balanced_dcn\"]\n",
    "dcn_experiments = DCN_Experiments(input_nodes, device)\n",
    "dcn_pd_models_eval_dict = dcn_experiments.evaluate_DCN_Model(tensor_treated_train_original,\n",
    "                                                                         tensor_control_train_original,\n",
    "                                                                         tensor_treated_balanced_dcn,\n",
    "                                                                         tensor_control_balanced_dcn,\n",
    "                                                                         data_loader_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1069, -0.1645,  0.0172,  ..., -0.1307, -0.1101, -0.0556],\n",
      "        [ 0.0490,  0.0936,  0.0930,  ...,  0.0752,  0.1481,  0.1392],\n",
      "        [ 0.0240,  0.0307, -0.0927,  ..., -0.0275, -0.1379, -0.1277],\n",
      "        ...,\n",
      "        [-0.0627,  0.1620,  0.1540,  ...,  0.1294,  0.1070,  0.0355],\n",
      "        [ 0.0689,  0.1006,  0.0201,  ...,  0.1242,  0.0982,  0.1066],\n",
      "        [-0.1529,  0.1238, -0.0671,  ..., -0.1003, -0.0016, -0.0652]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0808, -0.1195,  0.0818, -0.2292, -0.0500,  0.1617, -0.1112,  0.0155,\n",
      "        -0.1810,  0.0134, -0.1536,  0.2329,  0.0018,  0.0222, -0.2275,  0.1390,\n",
      "         0.1887,  0.2299, -0.1989, -0.0377,  0.2133,  0.1778, -0.1211,  0.2052,\n",
      "        -0.1015,  0.2338, -0.1719,  0.0123,  0.2329,  0.0818,  0.1936, -0.0243,\n",
      "         0.0345,  0.0178, -0.2121, -0.0125,  0.2221,  0.0077, -0.1962,  0.0106,\n",
      "        -0.1401, -0.1262,  0.0469, -0.1349,  0.0675,  0.2399,  0.0363,  0.0748,\n",
      "         0.1047,  0.0558, -0.1877, -0.2056,  0.2422,  0.1297, -0.1000, -0.0951,\n",
      "         0.1604, -0.1505, -0.1262, -0.1794,  0.1805, -0.0086, -0.1486,  0.0857,\n",
      "        -0.1059, -0.1112, -0.0722,  0.0419, -0.2092, -0.1722, -0.2285,  0.1804,\n",
      "         0.1669,  0.0143,  0.1974, -0.2370, -0.0389, -0.0819,  0.2167, -0.1229,\n",
      "         0.1531, -0.0629, -0.1265,  0.0237,  0.0896, -0.1687, -0.0558, -0.2332,\n",
      "         0.0700,  0.0201,  0.0539, -0.1203, -0.1364,  0.2121,  0.1000, -0.0598,\n",
      "         0.1411, -0.0986,  0.1556, -0.1620, -0.1312, -0.2412,  0.1698, -0.2084,\n",
      "        -0.1850, -0.0893, -0.2130, -0.1985, -0.0546,  0.2229,  0.1951, -0.1492,\n",
      "         0.1787,  0.0623,  0.2082, -0.1523,  0.2360, -0.2036,  0.1894,  0.0629,\n",
      "         0.1071,  0.0003,  0.0732,  0.1282,  0.0450,  0.0372, -0.1916,  0.1559,\n",
      "         0.0816,  0.2239, -0.1702, -0.0229, -0.0298, -0.1517,  0.0762,  0.1239,\n",
      "        -0.2375,  0.0856, -0.1417, -0.1356,  0.0026,  0.1761, -0.0233, -0.0336,\n",
      "        -0.0583,  0.2234, -0.1691, -0.2210, -0.2176,  0.0401,  0.1442, -0.0251,\n",
      "        -0.2162, -0.1517, -0.1670,  0.0360, -0.0944, -0.0399,  0.1928,  0.0272,\n",
      "         0.0906, -0.0578,  0.1985,  0.0603, -0.1664,  0.0159,  0.0019, -0.0999,\n",
      "         0.1787,  0.0279, -0.1768,  0.0375, -0.0851, -0.1247,  0.1820, -0.0932,\n",
      "         0.1534,  0.1464, -0.0179, -0.0263,  0.1412,  0.0429,  0.1716, -0.2048,\n",
      "         0.1577, -0.1516, -0.1669,  0.2093,  0.1842, -0.1238, -0.1655,  0.2280,\n",
      "         0.1940, -0.0396, -0.0583,  0.0753,  0.2236,  0.0654,  0.1394,  0.1257],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0808, -0.0214,  0.0188,  ...,  0.0181, -0.0988,  0.0100],\n",
      "        [-0.0989,  0.0346, -0.0996,  ..., -0.0662, -0.0765, -0.0525],\n",
      "        [ 0.0657,  0.1071,  0.0979,  ..., -0.0630, -0.0708,  0.0914],\n",
      "        ...,\n",
      "        [-0.0466,  0.0571, -0.0065,  ..., -0.0405,  0.0430,  0.0790],\n",
      "        [-0.1221, -0.0311,  0.1208,  ...,  0.0434, -0.0384,  0.0615],\n",
      "        [-0.0814,  0.0416, -0.0889,  ..., -0.0675,  0.0338,  0.0698]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0063,  0.0623, -0.0442, -0.0616, -0.0471, -0.0474, -0.0266, -0.0668,\n",
      "        -0.0476, -0.0365, -0.0309, -0.0705,  0.0424,  0.0662, -0.0515, -0.0319,\n",
      "        -0.0398, -0.0168,  0.0101,  0.0408,  0.0217,  0.0692,  0.0315, -0.0204,\n",
      "         0.0358, -0.0553,  0.0316, -0.0665, -0.0372, -0.0623,  0.0431,  0.0030,\n",
      "         0.0248,  0.0628,  0.0177, -0.0430,  0.0042, -0.0620, -0.0506, -0.0240,\n",
      "        -0.0195,  0.0423,  0.0446, -0.0343, -0.0146,  0.0355, -0.0137,  0.0396,\n",
      "         0.0500,  0.0646, -0.0399,  0.0685, -0.0321,  0.0382,  0.0612, -0.0021,\n",
      "        -0.0463,  0.0286, -0.0351,  0.0610, -0.0575,  0.0160, -0.0405,  0.0330,\n",
      "         0.0427,  0.0076,  0.0441,  0.0453,  0.0551,  0.0509,  0.0673,  0.0424,\n",
      "         0.0630, -0.0159, -0.0197,  0.0295, -0.0108,  0.0413,  0.0268, -0.0218,\n",
      "         0.0267,  0.0631,  0.0271, -0.0123, -0.0438, -0.0364,  0.0368,  0.0354,\n",
      "        -0.0477, -0.0621,  0.0080,  0.0086,  0.0074,  0.0504,  0.0484, -0.0632,\n",
      "        -0.0703,  0.0236, -0.0572, -0.0096, -0.0196,  0.0317,  0.0029,  0.0038,\n",
      "        -0.0559,  0.0193,  0.0542,  0.0177, -0.0176,  0.0420, -0.0131,  0.0521,\n",
      "        -0.0290,  0.0695, -0.0039,  0.0250,  0.0207,  0.0199, -0.0677,  0.0396,\n",
      "         0.0238, -0.0044,  0.0207, -0.0236, -0.0121, -0.0465,  0.0269,  0.0532,\n",
      "        -0.0206,  0.0597,  0.0085,  0.0226, -0.0354, -0.0495, -0.0237, -0.0563,\n",
      "         0.0545,  0.0011,  0.0191,  0.0169, -0.0355,  0.0335, -0.0701,  0.0106,\n",
      "        -0.0258, -0.0304, -0.0056,  0.0350, -0.0340, -0.0472, -0.0477,  0.0131,\n",
      "         0.0266, -0.0589, -0.0664, -0.0397,  0.0266, -0.0563,  0.0300, -0.0391,\n",
      "        -0.0527,  0.0028, -0.0051, -0.0585,  0.0154,  0.0116,  0.0216, -0.0696,\n",
      "         0.0154,  0.0537,  0.0097, -0.0543,  0.0050,  0.0535, -0.0544, -0.0185,\n",
      "         0.0266,  0.0321,  0.0233,  0.0488, -0.0148, -0.0332,  0.0021,  0.0458,\n",
      "         0.0243, -0.0482,  0.0453,  0.0053, -0.0001,  0.0693, -0.0690, -0.0529,\n",
      "         0.0027,  0.0396,  0.0125,  0.0037, -0.0180, -0.0607,  0.0663,  0.0485],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from DCN_Model import DCN_shared, DCN_Y1, DCN_Y0\n",
    "dcn_shared = DCN_shared(input_nodes=input_nodes).to(device)\n",
    "dcn_y1 = DCN_Y1().to(device)\n",
    "dcn_y0 = DCN_Y0().to(device)\n",
    "\n",
    "for parameter in dcn_shared.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_shared_path = \"/Users/shantanughosh/Desktop/Shantanu_MS/Research/Mattia_Prosperi/PM_GAN/Propensity_Match_using_GAN/IHDP_Shalit/Models/DCN_PD/DCN_PD_shared_iter_0.pth\"\n",
    "dcn_shared.load_state_dict(torch.load(model_shared_path,\n",
    "                                                   map_location=device))\n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
